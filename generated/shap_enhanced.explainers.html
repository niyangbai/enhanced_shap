<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html"><link rel="search" title="Search" href="../search.html"><link rel="next" title="shap_enhanced.explainers.ABSHAP" href="shap_enhanced.explainers.ABSHAP.html"><link rel="prev" title="shap_enhanced.base_explainer" href="shap_enhanced.base_explainer.html">
        <link rel="prefetch" href="../_static/fau_wiso_light.png" as="image">
        <link rel="prefetch" href="../_static/fau_wiso_dark.png" as="image">

    <!-- Generated with Sphinx 8.2.3 and Furo 2025.09.25 -->
        <title>shap_enhanced.explainers - Enhanced SHAP documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=d111a655" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=580074bf" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=8dab3a3b" />
    
    


<style>
  body {
    --color-code-background: #f2f2f2;
  --color-code-foreground: #1e1e1e;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle site navigation sidebar">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc" aria-label="Toggle table of contents sidebar">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <span class="icon"><svg><use href="#svg-menu"></use></svg></span>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Enhanced SHAP  documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="../_static/fau_wiso_light.png" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="../_static/fau_wiso_dark.png" alt="Dark Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Enhanced SHAP  documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1 current has-children"><a class="reference internal" href="../shap_enhanced_api.html">SHAP Enhanced API</a><input aria-label="Toggle navigation of SHAP Enhanced API" checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul class="current">
<li class="toctree-l2 current has-children"><a class="reference internal" href="shap_enhanced.html">shap_enhanced</a><input aria-label="Toggle navigation of shap_enhanced" checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="shap_enhanced.base_explainer.html">shap_enhanced.base_explainer</a></li>
<li class="toctree-l3 current has-children current-page"><a class="current reference internal" href="#">shap_enhanced.explainers</a><input aria-label="Toggle navigation of shap_enhanced.explainers" checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.explainers.ABSHAP.html">shap_enhanced.explainers.ABSHAP</a></li>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.explainers.AttnSHAP.html">shap_enhanced.explainers.AttnSHAP</a></li>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.explainers.BSHAP.html">shap_enhanced.explainers.BSHAP</a></li>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.explainers.CASHAP.html">shap_enhanced.explainers.CASHAP</a></li>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.explainers.CMSHAP.html">shap_enhanced.explainers.CMSHAP</a></li>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.explainers.ECSHAP.html">shap_enhanced.explainers.ECSHAP</a></li>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.explainers.ERSHAP.html">shap_enhanced.explainers.ERSHAP</a></li>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.explainers.ESSHAP.html">shap_enhanced.explainers.ESSHAP</a></li>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.explainers.LatentSHAP.html">shap_enhanced.explainers.LatentSHAP</a></li>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.explainers.MBSHAP.html">shap_enhanced.explainers.MBSHAP</a></li>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.explainers.RLSHAP.html">shap_enhanced.explainers.RLSHAP</a></li>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.explainers.SCSHAP.html">shap_enhanced.explainers.SCSHAP</a></li>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.explainers.SPSHAP.html">shap_enhanced.explainers.SPSHAP</a></li>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.explainers.SurroSHAP.html">shap_enhanced.explainers.SurroSHAP</a></li>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.explainers.TimeSHAP.html">shap_enhanced.explainers.TimeSHAP</a></li>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.explainers.hSHAP.html">shap_enhanced.explainers.hSHAP</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="shap_enhanced.tools.html">shap_enhanced.tools</a><input aria-label="Toggle navigation of shap_enhanced.tools" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.tools.comparison.html">shap_enhanced.tools.comparison</a></li>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.tools.datasets.html">shap_enhanced.tools.datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.tools.evaluation.html">shap_enhanced.tools.evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.tools.predefined_models.html">shap_enhanced.tools.predefined_models</a></li>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.tools.timer.html">shap_enhanced.tools.timer</a></li>
<li class="toctree-l4"><a class="reference internal" href="shap_enhanced.tools.visulization.html">shap_enhanced.tools.visulization</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/generated/shap_enhanced.explainers.rst.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="module-shap_enhanced.explainers">
<span id="shap-enhanced-explainers"></span><h1>shap_enhanced.explainers<a class="headerlink" href="#module-shap_enhanced.explainers" title="Link to this heading">¶</a></h1>
<section id="shap-explainers-collection">
<h2>SHAP Explainers Collection<a class="headerlink" href="#shap-explainers-collection" title="Link to this heading">¶</a></h2>
<section id="overview">
<h3>Overview<a class="headerlink" href="#overview" title="Link to this heading">¶</a></h3>
<p>This subpackage contains a suite of SHAP-style explainers, each designed to handle different data structures,
baseline strategies, and attribution mechanisms for interpretable machine learning. These explainers extend
beyond standard SHAP to provide specialized techniques for:</p>
<ul class="simple">
<li><p>Temporal and sequential data (e.g., <cite>TimeSHAP</cite>, <cite>LatentSHAP</cite>)</p></li>
<li><p>Sparse and discrete structures (e.g., <cite>SPSHAP</cite>, <cite>SCSHAP</cite>)</p></li>
<li><p>Reinforcement learning–based strategies (e.g., <cite>RLSHAP</cite>)</p></li>
<li><p>Surrogate model approximations (e.g., <cite>SurroSHAP</cite>)</p></li>
<li><p>Multi-baseline and enhanced SHAP variants</p></li>
</ul>
<p>Each module implements the <cite>BaseExplainer</cite> interface to ensure interoperability and consistent SHAP output.</p>
</section>
<section id="modules">
<h3>Modules<a class="headerlink" href="#modules" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong>LatentSHAP</strong>: Attribution in the latent space of an autoencoder.</p></li>
<li><p><strong>TimeSHAP</strong>: Pruned SHAP for long temporal sequences.</p></li>
<li><p><strong>SurroSHAP</strong>: Fast SHAP via surrogate regression.</p></li>
<li><p><strong>MBSHAP</strong>: Multi-baseline SHAP with per-sample reference sets.</p></li>
<li><p><strong>RLSHAP</strong>: SHAP value estimation via policy gradient masking.</p></li>
<li><p><strong>SPSHAP</strong>: Support-preserving masking for sparse inputs.</p></li>
<li><p><strong>SCSHAP</strong>: Sparse coalition enumeration for binary or one-hot inputs.</p></li>
<li><p><strong>… and more</strong>: Variants prefixed with a unique identifier (e.g., <cite>ESSHAP</cite>, <cite>ERSHAP</cite>) for experimentation.</p></li>
</ul>
</section>
<section id="usage">
<h3>Usage<a class="headerlink" href="#usage" title="Link to this heading">¶</a></h3>
<p>Import individual explainers or use the package to programmatically register all variants:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">shap_enhanced.explainers</span><span class="w"> </span><span class="kn">import</span> <span class="n">LatentSHAP</span><span class="p">,</span> <span class="n">TimeSHAP</span><span class="p">,</span> <span class="n">SurroSHAP</span>
</pre></div>
</div>
</section>
</section>
<dl class="py class">
<dt class="sig sig-object py" id="shap_enhanced.explainers.AdaptiveBaselineSHAPExplainer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">shap_enhanced.explainers.</span></span><span class="sig-name descname"><span class="pre">AdaptiveBaselineSHAPExplainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">background</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_baselines</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/ABSHAP.html#AdaptiveBaselineSHAPExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.AdaptiveBaselineSHAPExplainer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="shap_enhanced.base_explainer.html#shap_enhanced.base_explainer.BaseExplainer" title="shap_enhanced.base_explainer.BaseExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseExplainer</span></code></a></p>
<p>Adaptive Baseline SHAP (ABSHAP) Explainer for Dense and Sparse Features.</p>
<p>Implements a SHAP explainer that adaptively masks features based on their data distribution:
using mean-based masking for continuous features and sample-based masking for sparse or
categorical features. This ensures valid perturbations and avoids out-of-distribution artifacts.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Feature masking strategy can be determined automatically or manually specified.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Adaptive masking requires background data and introduces computational overhead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>Callable</em>) – Model to be explained. Should accept PyTorch tensors as input.</p></li>
<li><p><strong>background</strong> (<em>Union</em><em>[</em><em>np.ndarray</em><em>, </em><em>torch.Tensor</em><em>]</em>) – Background dataset for baseline sampling.
Shape: (N, F) or (N, T, F).</p></li>
<li><p><strong>n_baselines</strong> (<em>int</em>) – Number of baselines to sample per explanation. Default is 10.</p></li>
<li><p><strong>mask_strategy</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) – Either “auto” for detection or list per feature.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – PyTorch device identifier, e.g., “cpu” or “cuda”. Defaults to auto-detection.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="shap_enhanced.explainers.AdaptiveBaselineSHAPExplainer.expected_value">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">expected_value</span></span><a class="headerlink" href="#shap_enhanced.explainers.AdaptiveBaselineSHAPExplainer.expected_value" title="Link to this definition">¶</a></dt>
<dd><p>Optional property returning the expected model output on the background dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expected value if defined by the subclass, else None.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.AdaptiveBaselineSHAPExplainer.explain">
<span class="sig-name descname"><span class="pre">explain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap_enhanced.explainers.AdaptiveBaselineSHAPExplainer.explain" title="Link to this definition">¶</a></dt>
<dd><p>Alias to <cite>shap_values</cite> for flexibility and API compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Union</em><em>[</em><em>np.ndarray</em><em>, </em><em>torch.Tensor</em><em>, </em><em>list</em><em>]</em>) – Input samples to explain.</p></li>
<li><p><strong>kwargs</strong> – Additional arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[np.ndarray, list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.AdaptiveBaselineSHAPExplainer.shap_values">
<span class="sig-name descname"><span class="pre">shap_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nsamples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/ABSHAP.html#AdaptiveBaselineSHAPExplainer.shap_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.AdaptiveBaselineSHAPExplainer.shap_values" title="Link to this definition">¶</a></dt>
<dd><p>Estimates SHAP values for the given input <cite>X</cite> using the ABSHAP algorithm.</p>
<p>For each feature (t, f), estimates its marginal contribution by comparing model
outputs with and without the feature masked, averaging over sampled coalitions and baselines.</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\phi_{i} = \mathbb{E}_{S \subseteq N \setminus \{i\}} \left[ f(x_{S \cup \{i\}}) - f(x_S) \right]\]</div>
</div>
<p>The attributions are then normalized to match the output difference between the original and
fully-masked prediction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Union</em><em>[</em><em>np.ndarray</em><em>, </em><em>torch.Tensor</em><em>]</em>) – Input samples, shape (B, T, F) or (T, F).</p></li>
<li><p><strong>nsamples</strong> (<em>int</em>) – Number of masking combinations per feature. Default is 100.</p></li>
<li><p><strong>random_seed</strong> (<em>int</em>) – Seed for reproducibility. Default is 42.</p></li>
</ul>
</dd>
<dt class="field-even">Return np.ndarray<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values of shape (T, F) or (B, T, F).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></span></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="shap_enhanced.explainers.AttnSHAPExplainer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">shap_enhanced.explainers.</span></span><span class="sig-name descname"><span class="pre">AttnSHAPExplainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">background</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_attention</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proxy_attention</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gradient'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/AttnSHAP.html#AttnSHAPExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.AttnSHAPExplainer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="shap_enhanced.base_explainer.html#shap_enhanced.base_explainer.BaseExplainer" title="shap_enhanced.base_explainer.BaseExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseExplainer</span></code></a></p>
<p>Attention-Guided SHAP Explainer for structured/sequential data.</p>
<p>This class implements an extension to the SHAP framework that leverages attention mechanisms
(either native to the model or via proxy strategies) to guide the coalition sampling process,
focusing attribution on informative feature regions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – PyTorch model to be explained.</p></li>
<li><p><strong>background</strong> – Background dataset used for SHAP estimation.</p></li>
<li><p><strong>use_attention</strong> (<em>bool</em>) – If True, uses attention weights (or proxy) for guiding feature masking.</p></li>
<li><p><strong>proxy_attention</strong> (<em>str</em>) – Strategy to approximate attention when model does not provide it.
Options: “gradient”, “input”, “perturb”.</p></li>
<li><p><strong>device</strong> – Computation device (‘cuda’ or ‘cpu’).</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="shap_enhanced.explainers.AttnSHAPExplainer.expected_value">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">expected_value</span></span><a class="headerlink" href="#shap_enhanced.explainers.AttnSHAPExplainer.expected_value" title="Link to this definition">¶</a></dt>
<dd><p>Optional property returning the expected model output on the background dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expected value if defined by the subclass, else None.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.AttnSHAPExplainer.explain">
<span class="sig-name descname"><span class="pre">explain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap_enhanced.explainers.AttnSHAPExplainer.explain" title="Link to this definition">¶</a></dt>
<dd><p>Alias to <cite>shap_values</cite> for flexibility and API compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Union</em><em>[</em><em>np.ndarray</em><em>, </em><em>torch.Tensor</em><em>, </em><em>list</em><em>]</em>) – Input samples to explain.</p></li>
<li><p><strong>kwargs</strong> – Additional arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[np.ndarray, list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.AttnSHAPExplainer.shap_values">
<span class="sig-name descname"><span class="pre">shap_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nsamples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coalition_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_additivity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/AttnSHAP.html#AttnSHAPExplainer.shap_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.AttnSHAPExplainer.shap_values" title="Link to this definition">¶</a></dt>
<dd><p>Compute SHAP values using attention-guided or proxy-guided coalition sampling.</p>
<p>For each feature at each time step, it estimates the marginal contribution by comparing
model outputs when the feature is masked vs. when it is included in a masked coalition.
Sampling is optionally biased using attention scores.</p>
<p>The final attributions are normalized to satisfy SHAP’s additivity constraint:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\sum_{t=1}^T \sum_{f=1}^F \phi_{t,f} \approx f(x) - f(x_{masked})\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>np.ndarray</em><em> or </em><em>torch.Tensor</em>) – Input data of shape (B, T, F) or (T, F)</p></li>
<li><p><strong>nsamples</strong> (<em>int</em>) – Number of coalitions sampled per feature.</p></li>
<li><p><strong>coalition_size</strong> (<em>int</em>) – Number of features in each sampled coalition.</p></li>
<li><p><strong>check_additivity</strong> (<em>bool</em>) – Whether to print additivity check results.</p></li>
<li><p><strong>random_seed</strong> (<em>int</em>) – Seed for reproducible coalition sampling.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values of shape (T, F) for single input or (B, T, F) for batch.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="shap_enhanced.explainers.BShapExplainer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">shap_enhanced.explainers.</span></span><span class="sig-name descname"><span class="pre">BShapExplainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'random'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/BSHAP.html#BShapExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.BShapExplainer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="shap_enhanced.base_explainer.html#shap_enhanced.base_explainer.BaseExplainer" title="shap_enhanced.base_explainer.BaseExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseExplainer</span></code></a></p>
<p>BShap: Distribution-Free SHAP Explainer for Sequential Models</p>
<p>Implements a SHAP-based attribution method that avoids empirical data distribution assumptions
by applying synthetic masking strategies (e.g., uniform noise, Gaussian noise, or zero).
This is useful for evaluating model robustness or interpretability in data-agnostic contexts.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – Sequence model to explain.</p></li>
<li><p><strong>input_range</strong> (<em>tuple</em><em> or </em><em>(</em><em>np.ndarray</em><em>, </em><em>np.ndarray</em><em>)</em>) – Tuple of (min, max) or arrays defining per-feature value bounds. Used for random masking.</p></li>
<li><p><strong>n_samples</strong> (<em>int</em>) – Number of coalitions sampled per feature.</p></li>
<li><p><strong>mask_strategy</strong> (<em>str</em>) – Masking strategy: ‘random’, ‘noise’, or ‘zero’.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – Device identifier, e.g., ‘cpu’ or ‘cuda’.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="shap_enhanced.explainers.BShapExplainer.expected_value">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">expected_value</span></span><a class="headerlink" href="#shap_enhanced.explainers.BShapExplainer.expected_value" title="Link to this definition">¶</a></dt>
<dd><p>Optional property returning the expected model output on the background dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expected value if defined by the subclass, else None.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.BShapExplainer.explain">
<span class="sig-name descname"><span class="pre">explain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap_enhanced.explainers.BShapExplainer.explain" title="Link to this definition">¶</a></dt>
<dd><p>Alias to <cite>shap_values</cite> for flexibility and API compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Union</em><em>[</em><em>np.ndarray</em><em>, </em><em>torch.Tensor</em><em>, </em><em>list</em><em>]</em>) – Input samples to explain.</p></li>
<li><p><strong>kwargs</strong> – Additional arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[np.ndarray, list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.BShapExplainer.shap_values">
<span class="sig-name descname"><span class="pre">shap_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nsamples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_additivity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/BSHAP.html#BShapExplainer.shap_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.BShapExplainer.shap_values" title="Link to this definition">¶</a></dt>
<dd><p>Compute SHAP values using distribution-free perturbations.</p>
<p>Estimates marginal feature contributions by averaging differences between model outputs
under masked coalitions. Uses synthetic masking based on the configured strategy
without any reliance on background data statistics.</p>
<p>Final attributions are normalized to satisfy the SHAP additivity constraint:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\sum_{t=1}^T \sum_{f=1}^F \phi_{t,f} \approx f(x) - f(x_{\text{masked}})\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>np.ndarray</em><em> or </em><em>torch.Tensor</em>) – Input of shape (T, F) or (B, T, F)</p></li>
<li><p><strong>nsamples</strong> (<em>int</em>) – Number of coalition samples per feature (defaults to self.n_samples).</p></li>
<li><p><strong>check_additivity</strong> (<em>bool</em>) – Print diagnostic message for SHAP sum vs. model delta.</p></li>
<li><p><strong>random_seed</strong> (<em>int</em>) – Seed for reproducibility.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values of shape (T, F) or (B, T, F)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="shap_enhanced.explainers.CoalitionAwareSHAPExplainer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">shap_enhanced.explainers.</span></span><span class="sig-name descname"><span class="pre">CoalitionAwareSHAPExplainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">background</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'zero'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">imputer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/CASHAP.html#CoalitionAwareSHAPExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.CoalitionAwareSHAPExplainer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="shap_enhanced.base_explainer.html#shap_enhanced.base_explainer.BaseExplainer" title="shap_enhanced.base_explainer.BaseExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseExplainer</span></code></a></p>
<p>Coalition-Aware SHAP (CASHAP) Explainer</p>
<p>Estimates Shapley values for models processing structured inputs (e.g., time-series, sequences)
by sampling coalitions of feature-time pairs and computing their marginal contributions
using various imputation strategies.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>Any</em>) – Model to be explained.</p></li>
<li><p><strong>background</strong> (<em>Optional</em><em>[</em><em>np.ndarray</em><em> or </em><em>torch.Tensor</em><em>]</em>) – Background data used for mean imputation strategy.</p></li>
<li><p><strong>mask_strategy</strong> (<em>str</em>) – Strategy for imputing/masking feature-time pairs.
Options: ‘zero’, ‘mean’, or ‘custom’.</p></li>
<li><p><strong>imputer</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>]</em>) – Custom callable for imputation. Required if <cite>mask_strategy</cite> is ‘custom’.</p></li>
<li><p><strong>device</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – Device on which computation runs. Defaults to ‘cuda’ if available.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="shap_enhanced.explainers.CoalitionAwareSHAPExplainer.expected_value">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">expected_value</span></span><a class="headerlink" href="#shap_enhanced.explainers.CoalitionAwareSHAPExplainer.expected_value" title="Link to this definition">¶</a></dt>
<dd><p>Optional property returning the expected model output on the background dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expected value if defined by the subclass, else None.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.CoalitionAwareSHAPExplainer.explain">
<span class="sig-name descname"><span class="pre">explain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap_enhanced.explainers.CoalitionAwareSHAPExplainer.explain" title="Link to this definition">¶</a></dt>
<dd><p>Alias to <cite>shap_values</cite> for flexibility and API compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Union</em><em>[</em><em>np.ndarray</em><em>, </em><em>torch.Tensor</em><em>, </em><em>list</em><em>]</em>) – Input samples to explain.</p></li>
<li><p><strong>kwargs</strong> – Additional arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[np.ndarray, list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.CoalitionAwareSHAPExplainer.shap_values">
<span class="sig-name descname"><span class="pre">shap_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nsamples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coalition_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_additivity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/CASHAP.html#CoalitionAwareSHAPExplainer.shap_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.CoalitionAwareSHAPExplainer.shap_values" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></span></p>
<p>Compute CASHAP Shapley values for structured inputs via coalition-aware sampling.</p>
<p>For each feature-time pair ((t, f)), randomly sample coalitions excluding ((t, f)),
compute model outputs with and without the pair added, and average the marginal contributions.
Attribution values are normalized so their total matches the model output difference
between the original and fully-masked input.</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\phi_{t,f} pprox \mathbb{E}_{C \subseteq (T        imes F) \setminus \{(t,f)\}} \left[
    f(C \cup \{(t,f)\}) - f(C)\]</div>
</div>
</p>
</dd>
</dl>
<p>ight]</p>
<blockquote>
<div><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Normalization ensures:
sum_{t=1}^T sum_{f=1}^F phi_{t,f} pprox f(x) - f(x_{    ext{masked}})</p>
</div>
</div></blockquote>
<dl class="field-list simple">
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="shap_enhanced.explainers.ContextualMaskingSHAPExplainer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">shap_enhanced.explainers.</span></span><span class="sig-name descname"><span class="pre">ContextualMaskingSHAPExplainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/CMSHAP.html#ContextualMaskingSHAPExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.ContextualMaskingSHAPExplainer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="shap_enhanced.base_explainer.html#shap_enhanced.base_explainer.BaseExplainer" title="shap_enhanced.base_explainer.BaseExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseExplainer</span></code></a></p>
<p>Contextual Masking SHAP (CM-SHAP) Explainer for Sequential Models</p>
<p>Estimates SHAP values for sequential inputs by replacing masked feature values with
interpolated values from neighboring time steps. This context-aware masking strategy
preserves temporal coherence and enables more realistic feature perturbation in time-series data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>Any</em>) – Model to explain. Must accept NumPy arrays or PyTorch tensors.</p></li>
<li><p><strong>device</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – Device to perform computations on (‘cpu’ or ‘cuda’). Defaults to ‘cuda’ if available.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="shap_enhanced.explainers.ContextualMaskingSHAPExplainer.expected_value">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">expected_value</span></span><a class="headerlink" href="#shap_enhanced.explainers.ContextualMaskingSHAPExplainer.expected_value" title="Link to this definition">¶</a></dt>
<dd><p>Optional property returning the expected model output on the background dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expected value if defined by the subclass, else None.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.ContextualMaskingSHAPExplainer.explain">
<span class="sig-name descname"><span class="pre">explain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap_enhanced.explainers.ContextualMaskingSHAPExplainer.explain" title="Link to this definition">¶</a></dt>
<dd><p>Alias to <cite>shap_values</cite> for flexibility and API compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Union</em><em>[</em><em>np.ndarray</em><em>, </em><em>torch.Tensor</em><em>, </em><em>list</em><em>]</em>) – Input samples to explain.</p></li>
<li><p><strong>kwargs</strong> – Additional arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[np.ndarray, list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.ContextualMaskingSHAPExplainer.shap_values">
<span class="sig-name descname"><span class="pre">shap_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nsamples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_additivity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/CMSHAP.html#ContextualMaskingSHAPExplainer.shap_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.ContextualMaskingSHAPExplainer.shap_values" title="Link to this definition">¶</a></dt>
<dd><p>Estimate SHAP values using contextual (interpolated) masking.</p>
<p>Each feature-time pair (t, f) is evaluated by sampling coalitions of other
positions, applying context-aware masking, and averaging the difference
in model outputs when (t, f) is added to the coalition.</p>
<p>Interpolation strategy ensures continuity in time series by replacing masked
values with averages of adjacent time steps:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\begin{split}x_{t,f}^{masked} =
\begin{cases}
    x_{t+1,f}, &amp; \text{if } t = 0 \\
    x_{t-1,f}, &amp; \text{if } t = T-1 \\
    \frac{x_{t-1,f} + x_{t+1,f}}{2}, &amp; \text{otherwise}
\end{cases}\end{split}\]</div>
</div>
<p>Final attributions are normalized such that:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\sum_{t=1}^T \sum_{f=1}^F \phi_{t,f} \approx f(x) - f(x_{masked})\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>np.ndarray</em><em> or </em><em>torch.Tensor</em>) – Input array of shape (T, F) or (B, T, F)</p></li>
<li><p><strong>nsamples</strong> (<em>int</em>) – Number of sampled coalitions per position.</p></li>
<li><p><strong>check_additivity</strong> (<em>bool</em>) – Whether to normalize SHAP values to match output difference.</p></li>
<li><p><strong>random_seed</strong> (<em>int</em>) – Random seed for reproducibility.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values with same shape as input.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="shap_enhanced.explainers.ERSHAPExplainer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">shap_enhanced.explainers.</span></span><span class="sig-name descname"><span class="pre">ERSHAPExplainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">background</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_coalitions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weighting</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'uniform'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_importance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/ERSHAP.html#ERSHAPExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.ERSHAPExplainer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="shap_enhanced.base_explainer.html#shap_enhanced.base_explainer.BaseExplainer" title="shap_enhanced.base_explainer.BaseExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseExplainer</span></code></a></p>
<p>ER-SHAP: Ensemble of Random SHAP Explainer</p>
<p>An efficient approximation of Shapley values using random coalition sampling over
time-feature positions. Supports uniform and weighted sampling strategies and flexible
masking (zero or mean) to generate perturbed inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>Any</em>) – Model to explain, compatible with PyTorch tensors.</p></li>
<li><p><strong>background</strong> (<em>np.ndarray</em><em> or </em><em>torch.Tensor</em>) – Background dataset for mean imputation; shape (N, T, F).</p></li>
<li><p><strong>n_coalitions</strong> (<em>int</em>) – Number of coalitions to sample per (t, f) position.</p></li>
<li><p><strong>mask_strategy</strong> (<em>str</em>) – Masking method: ‘zero’ or ‘mean’.</p></li>
<li><p><strong>weighting</strong> (<em>str</em>) – Sampling scheme: ‘uniform’, ‘frequency’, or ‘importance’.</p></li>
<li><p><strong>feature_importance</strong> (<em>Optional</em><em>[</em><em>np.ndarray</em><em>]</em>) – Prior feature importances for weighted sampling; shape (T, F).</p></li>
<li><p><strong>device</strong> (<em>str</em>) – Device identifier, ‘cpu’ or ‘cuda’.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="shap_enhanced.explainers.ERSHAPExplainer.expected_value">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">expected_value</span></span><a class="headerlink" href="#shap_enhanced.explainers.ERSHAPExplainer.expected_value" title="Link to this definition">¶</a></dt>
<dd><p>Optional property returning the expected model output on the background dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expected value if defined by the subclass, else None.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.ERSHAPExplainer.explain">
<span class="sig-name descname"><span class="pre">explain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap_enhanced.explainers.ERSHAPExplainer.explain" title="Link to this definition">¶</a></dt>
<dd><p>Alias to <cite>shap_values</cite> for flexibility and API compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Union</em><em>[</em><em>np.ndarray</em><em>, </em><em>torch.Tensor</em><em>, </em><em>list</em><em>]</em>) – Input samples to explain.</p></li>
<li><p><strong>kwargs</strong> – Additional arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[np.ndarray, list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.ERSHAPExplainer.shap_values">
<span class="sig-name descname"><span class="pre">shap_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_additivity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/ERSHAP.html#ERSHAPExplainer.shap_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.ERSHAPExplainer.shap_values" title="Link to this definition">¶</a></dt>
<dd><p>Compute SHAP values via random coalition sampling.</p>
<p>For each position (t, f), sample coalitions of other positions,
compute marginal contributions, and average over samples.
Attributions are normalized to satisfy:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\sum_{t=1}^T \sum_{f=1}^F \phi_{t,f} \approx f(x) - f(x_{masked})\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>np.ndarray</em><em> or </em><em>torch.Tensor</em>) – Input array or tensor of shape (T, F) or (B, T, F).</p></li>
<li><p><strong>check_additivity</strong> (<em>bool</em>) – Whether to apply normalization for additivity.</p></li>
<li><p><strong>random_seed</strong> (<em>int</em>) – Seed for reproducibility.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values of shape (T, F) or (B, T, F).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="shap_enhanced.explainers.EmpiricalConditionalSHAPExplainer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">shap_enhanced.explainers.</span></span><span class="sig-name descname"><span class="pre">EmpiricalConditionalSHAPExplainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">background</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_unmatched</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_closest</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/ECSHAP.html#EmpiricalConditionalSHAPExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.EmpiricalConditionalSHAPExplainer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="shap_enhanced.base_explainer.html#shap_enhanced.base_explainer.BaseExplainer" title="shap_enhanced.base_explainer.BaseExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseExplainer</span></code></a></p>
<p>Empirical Conditional SHAP (EC-SHAP) Explainer for Discrete Data</p>
<p>This explainer estimates Shapley values for discrete (e.g., categorical, binary, or one-hot)
feature inputs by imputing masked features from a background dataset using conditional matching.
It ensures perturbed samples remain within the data manifold, preserving interpretability.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>Any</em>) – Model to explain, must support PyTorch tensors as input.</p></li>
<li><p><strong>background</strong> (<em>np.ndarray</em><em> or </em><em>torch.Tensor</em>) – Background dataset used for empirical conditional imputation.</p></li>
<li><p><strong>skip_unmatched</strong> (<em>bool</em>) – If True, skip coalitions where no matching background sample exists.</p></li>
<li><p><strong>use_closest</strong> (<em>bool</em>) – If True, use the closest (Hamming distance) background sample when no exact match is found.</p></li>
<li><p><strong>device</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – Device on which to run the model (‘cpu’ or ‘cuda’).</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="shap_enhanced.explainers.EmpiricalConditionalSHAPExplainer.expected_value">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">expected_value</span></span><a class="headerlink" href="#shap_enhanced.explainers.EmpiricalConditionalSHAPExplainer.expected_value" title="Link to this definition">¶</a></dt>
<dd><p>Optional property returning the expected model output on the background dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expected value if defined by the subclass, else None.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.EmpiricalConditionalSHAPExplainer.explain">
<span class="sig-name descname"><span class="pre">explain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap_enhanced.explainers.EmpiricalConditionalSHAPExplainer.explain" title="Link to this definition">¶</a></dt>
<dd><p>Alias to <cite>shap_values</cite> for flexibility and API compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Union</em><em>[</em><em>np.ndarray</em><em>, </em><em>torch.Tensor</em><em>, </em><em>list</em><em>]</em>) – Input samples to explain.</p></li>
<li><p><strong>kwargs</strong> – Additional arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[np.ndarray, list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.EmpiricalConditionalSHAPExplainer.shap_values">
<span class="sig-name descname"><span class="pre">shap_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nsamples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_additivity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/ECSHAP.html#EmpiricalConditionalSHAPExplainer.shap_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.EmpiricalConditionalSHAPExplainer.shap_values" title="Link to this definition">¶</a></dt>
<dd><p>Estimate SHAP values using empirical conditional imputation.</p>
<p>For each feature-time index (t, f), this method:
- Samples coalitions of other features.
- Finds background samples matching the unmasked portion of the input.
- Imputes masked values with corresponding values from the matched sample.
- Computes model output with and without the target feature masked.
- Averages the differences over multiple coalitions.</p>
<p>Normalization ensures:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\sum_{t=1}^T \sum_{f=1}^F \phi_{t,f} \approx f(x) - f(x_{\text{masked}})\]</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If no exact match is found and <cite>use_closest</cite> is False, the coalition may be skipped.
For continuous-looking data, the method will fallback to mean imputation.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>np.ndarray</em><em> or </em><em>torch.Tensor</em>) – Input data of shape (T, F) or (B, T, F)</p></li>
<li><p><strong>nsamples</strong> (<em>int</em>) – Number of coalitions to sample per feature.</p></li>
<li><p><strong>check_additivity</strong> (<em>bool</em>) – Whether to rescale SHAP values to match model output difference.</p></li>
<li><p><strong>random_seed</strong> (<em>int</em>) – Seed for reproducibility.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values of shape (T, F) or (B, T, F)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="shap_enhanced.explainers.EnsembleSHAPWithNoise">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">shap_enhanced.explainers.</span></span><span class="sig-name descname"><span class="pre">EnsembleSHAPWithNoise</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">background</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">explainer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">explainer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_runs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_target</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'input'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/ESSHAP.html#EnsembleSHAPWithNoise"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.EnsembleSHAPWithNoise" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="shap_enhanced.base_explainer.html#shap_enhanced.base_explainer.BaseExplainer" title="shap_enhanced.base_explainer.BaseExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseExplainer</span></code></a></p>
<p>EnsembleSHAPWithNoise: Robust Ensemble Wrapper for SHAP/Custom Explainers</p>
<p>This class enhances the stability of SHAP (SHapley Additive exPlanations) values by performing multiple runs
with Gaussian noise applied to inputs and/or background data, and aggregating the results. It wraps around
standard SHAP explainers or custom user-defined ones, making them more robust in the presence of
sensitivity or instability.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This class automatically handles input conversion between NumPy and PyTorch, depending on the explainer type.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The model to explain.</p></li>
<li><p><strong>background</strong> – Background data used for SHAP attribution (can be None if not required).</p></li>
<li><p><strong>explainer_class</strong> – The SHAP or custom explainer class to wrap. Defaults to <cite>shap.DeepExplainer</cite>.</p></li>
<li><p><strong>explainer_kwargs</strong> – Dictionary of keyword arguments to pass to the explainer during instantiation.</p></li>
<li><p><strong>n_runs</strong> (<em>int</em>) – Number of noisy runs to perform for ensemble aggregation.</p></li>
<li><p><strong>noise_level</strong> (<em>float</em>) – Standard deviation of Gaussian noise to inject.</p></li>
<li><p><strong>noise_target</strong> (<em>str</em>) – Target for noise injection: “input”, “background”, or “both”.</p></li>
<li><p><strong>aggregation</strong> (<em>str</em>) – Aggregation method across runs: “mean” or “median”.</p></li>
<li><p><strong>device</strong> – Device context (e.g., ‘cpu’, ‘cuda’) for tensor-based explainers. Defaults to available GPU or CPU.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="shap_enhanced.explainers.EnsembleSHAPWithNoise.expected_value">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">expected_value</span></span><a class="headerlink" href="#shap_enhanced.explainers.EnsembleSHAPWithNoise.expected_value" title="Link to this definition">¶</a></dt>
<dd><p>Optional property returning the expected model output on the background dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expected value if defined by the subclass, else None.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.EnsembleSHAPWithNoise.explain">
<span class="sig-name descname"><span class="pre">explain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap_enhanced.explainers.EnsembleSHAPWithNoise.explain" title="Link to this definition">¶</a></dt>
<dd><p>Alias to <cite>shap_values</cite> for flexibility and API compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Union</em><em>[</em><em>np.ndarray</em><em>, </em><em>torch.Tensor</em><em>, </em><em>list</em><em>]</em>) – Input samples to explain.</p></li>
<li><p><strong>kwargs</strong> – Additional arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[np.ndarray, list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.EnsembleSHAPWithNoise.shap_values">
<span class="sig-name descname"><span class="pre">shap_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/ESSHAP.html#EnsembleSHAPWithNoise.shap_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.EnsembleSHAPWithNoise.shap_values" title="Link to this definition">¶</a></dt>
<dd><p>Compute noise-robust SHAP values via ensemble averaging over multiple noisy runs.</p>
<p>For each run, Gaussian noise is added to the input and/or background (as configured),
then the SHAP explainer is applied to compute attribution values. These are aggregated
(mean or median) to produce a stable final output.</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\begin{split}\text{Attribution}_{final}(i) =
\begin{cases}
    \frac{1}{N} \sum_{j=1}^N \text{SHAP}_j(i) &amp; \text{if aggregation = mean} \\
    \text{median}\{\text{SHAP}_1(i), \ldots, \text{SHAP}_N(i)\} &amp; \text{if aggregation = median}
\end{cases}\end{split}\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>np.ndarray</em><em> or </em><em>torch.Tensor</em>) – Input sample(s) to explain (NumPy array or torch.Tensor).</p></li>
<li><p><strong>kwargs</strong> – Additional keyword arguments passed to the underlying explainer’s <cite>shap_values</cite> method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Aggregated attribution values across ensemble runs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="shap_enhanced.explainers.HShapExplainer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">shap_enhanced.explainers.</span></span><span class="sig-name descname"><span class="pre">HShapExplainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">background</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hierarchy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/hSHAP.html#HShapExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.HShapExplainer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="shap_enhanced.base_explainer.html#shap_enhanced.base_explainer.BaseExplainer" title="shap_enhanced.base_explainer.BaseExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseExplainer</span></code></a></p>
<p>HShapExplainer: Hierarchical SHAP Explainer</p>
<p>Implements the h-SHAP algorithm, which recursively computes SHAP values over structured
groups of features using hierarchical masking. Suitable for time-series or block-structured
feature inputs where interpretability benefits from grouped attributions.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Features can be masked using hard zero-masking or soft imputation via background means.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – Model to explain.</p></li>
<li><p><strong>background</strong> (<em>np.ndarray</em><em> or </em><em>torch.Tensor</em>) – Background dataset for mean imputation. Shape: (N, T, F).</p></li>
<li><p><strong>hierarchy</strong> (<em>list</em>) – Nested list of feature index groups (e.g., [[(t1, f1), (t2, f2)], …]).</p></li>
<li><p><strong>mask_strategy</strong> (<em>str</em>) – Either “mean” for imputation or “zero” for hard masking.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – Device context, e.g., “cuda” or “cpu”.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="shap_enhanced.explainers.HShapExplainer.expected_value">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">expected_value</span></span><a class="headerlink" href="#shap_enhanced.explainers.HShapExplainer.expected_value" title="Link to this definition">¶</a></dt>
<dd><p>Optional property returning the expected model output on the background dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expected value if defined by the subclass, else None.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.HShapExplainer.explain">
<span class="sig-name descname"><span class="pre">explain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap_enhanced.explainers.HShapExplainer.explain" title="Link to this definition">¶</a></dt>
<dd><p>Alias to <cite>shap_values</cite> for flexibility and API compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Union</em><em>[</em><em>np.ndarray</em><em>, </em><em>torch.Tensor</em><em>, </em><em>list</em><em>]</em>) – Input samples to explain.</p></li>
<li><p><strong>kwargs</strong> – Additional arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[np.ndarray, list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.HShapExplainer.shap_values">
<span class="sig-name descname"><span class="pre">shap_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nsamples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_additivity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/hSHAP.html#HShapExplainer.shap_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.HShapExplainer.shap_values" title="Link to this definition">¶</a></dt>
<dd><p>Compute hierarchical SHAP values for a batch of inputs.</p>
<p>The method recursively attributes model output to hierarchical feature groups.
It also ensures additivity via normalization of final attributions.</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\sum_{i=1}^{TF} \phi_i = f(x) - f(x_{\text{masked}})\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>np.ndarray</em><em> or </em><em>torch.Tensor</em>) – Input batch, shape (B, T, F) or single instance (T, F).</p></li>
<li><p><strong>nsamples</strong> (<em>int</em>) – Number of Monte Carlo samples per group.</p></li>
<li><p><strong>check_additivity</strong> (<em>bool</em>) – If True, prints additivity check summary.</p></li>
<li><p><strong>random_seed</strong> (<em>int</em>) – Seed for reproducible sampling.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values, same shape as <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="shap_enhanced.explainers.LatentSHAPExplainer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">shap_enhanced.explainers.</span></span><span class="sig-name descname"><span class="pre">LatentSHAPExplainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_explainer_class</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">background</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_explainer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/LatentSHAP.html#LatentSHAPExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.LatentSHAPExplainer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="shap_enhanced.base_explainer.html#shap_enhanced.base_explainer.BaseExplainer" title="shap_enhanced.base_explainer.BaseExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseExplainer</span></code></a></p>
<p>LatentSHAPExplainer: SHAP Attribution in Autoencoded Latent Space</p>
<p>This class applies SHAP to the latent space of an autoencoder and projects the resulting attributions
back into input space using the decoder’s Jacobian. It is especially useful for high-dimensional,
structured inputs (e.g., time series) where direct SHAP attribution is noisy or expensive.</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\phi_{\text{input}} = J_{\text{decoder}}(z) \cdot \phi_{\text{latent}}\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – Downstream predictive model, operating in input space.</p></li>
<li><p><strong>encoder</strong> (<em>torch.nn.Module</em>) – Encoder network mapping input to latent space.</p></li>
<li><p><strong>decoder</strong> (<em>torch.nn.Module</em>) – Decoder network mapping latent to input space.</p></li>
<li><p><strong>base_explainer_class</strong> – SHAP explainer class (e.g., GradientExplainer).</p></li>
<li><p><strong>background</strong> (<em>np.ndarray</em><em> or </em><em>torch.Tensor</em>) – Background dataset (N, T, F) used for SHAP estimation.</p></li>
<li><p><strong>device</strong> – Device context (e.g., ‘cpu’ or ‘cuda’).</p></li>
<li><p><strong>base_explainer_kwargs</strong> (<em>dict</em>) – Optional dictionary of kwargs passed to SHAP explainer.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="shap_enhanced.explainers.LatentSHAPExplainer.expected_value">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">expected_value</span></span><a class="headerlink" href="#shap_enhanced.explainers.LatentSHAPExplainer.expected_value" title="Link to this definition">¶</a></dt>
<dd><p>Optional property returning the expected model output on the background dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expected value if defined by the subclass, else None.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.LatentSHAPExplainer.explain">
<span class="sig-name descname"><span class="pre">explain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap_enhanced.explainers.LatentSHAPExplainer.explain" title="Link to this definition">¶</a></dt>
<dd><p>Alias to <cite>shap_values</cite> for flexibility and API compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Union</em><em>[</em><em>np.ndarray</em><em>, </em><em>torch.Tensor</em><em>, </em><em>list</em><em>]</em>) – Input samples to explain.</p></li>
<li><p><strong>kwargs</strong> – Additional arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[np.ndarray, list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.LatentSHAPExplainer.shap_values">
<span class="sig-name descname"><span class="pre">shap_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/LatentSHAP.html#LatentSHAPExplainer.shap_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.LatentSHAPExplainer.shap_values" title="Link to this definition">¶</a></dt>
<dd><p>Compute SHAP values in latent space and project them to input space.</p>
<p>Steps:
1. Encode input and background into latent space.
2. Run SHAP (e.g., GradientExplainer) on latent input.
3. Compute Jacobian from latent to input.
4. Project latent SHAP values using the Jacobian.
5. Return attributions with original input shape.</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\phi_{\text{input}} = J(z) \cdot \phi_{\text{latent}}\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>np.ndarray</em><em> or </em><em>torch.Tensor</em>) – Input sample(s), shape (T, F) or (B, T, F)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP attributions in input space.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="shap_enhanced.explainers.NearestNeighborMultiBaselineSHAP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">shap_enhanced.explainers.</span></span><span class="sig-name descname"><span class="pre">NearestNeighborMultiBaselineSHAP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_explainer_class</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">background</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_baselines</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_explainer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/MBSHAP.html#NearestNeighborMultiBaselineSHAP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.NearestNeighborMultiBaselineSHAP" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="shap_enhanced.base_explainer.html#shap_enhanced.base_explainer.BaseExplainer" title="shap_enhanced.base_explainer.BaseExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseExplainer</span></code></a></p>
<p>NearestNeighborMultiBaselineSHAP: Multi-Baseline SHAP Explainer</p>
<p>This explainer improves attribution robustness by selecting the K nearest neighbors
from a background dataset as baselines for each input sample, computing SHAP values
individually for each baseline, and then averaging the results.</p>
<p>It is compatible with various SHAP explainers (e.g., <cite>DeepExplainer</cite>, <cite>GradientExplainer</cite>, <cite>KernelExplainer</cite>)
and automatically adapts input types and parameter formats accordingly.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Baseline selection is input-dependent and done per sample using L2 distance in flattened input space.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_explainer_class</strong> – The SHAP explainer class to use (e.g., <cite>shap.DeepExplainer</cite>).</p></li>
<li><p><strong>model</strong> (<em>Any</em>) – The predictive model to explain.</p></li>
<li><p><strong>background</strong> (<em>np.ndarray</em>) – Background dataset (N, …) for nearest neighbor selection.</p></li>
<li><p><strong>n_baselines</strong> (<em>int</em>) – Number of nearest neighbor baselines to use per sample.</p></li>
<li><p><strong>base_explainer_kwargs</strong> (<em>dict</em><em> or </em><em>None</em>) – Additional keyword arguments passed to the SHAP explainer.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – Device context for torch-based explainers (‘cpu’ or ‘cuda’).</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="shap_enhanced.explainers.NearestNeighborMultiBaselineSHAP.expected_value">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">expected_value</span></span><a class="headerlink" href="#shap_enhanced.explainers.NearestNeighborMultiBaselineSHAP.expected_value" title="Link to this definition">¶</a></dt>
<dd><p>Optional property returning the expected model output on the background dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expected value if defined by the subclass, else None.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.NearestNeighborMultiBaselineSHAP.explain">
<span class="sig-name descname"><span class="pre">explain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap_enhanced.explainers.NearestNeighborMultiBaselineSHAP.explain" title="Link to this definition">¶</a></dt>
<dd><p>Alias to <cite>shap_values</cite> for flexibility and API compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Union</em><em>[</em><em>np.ndarray</em><em>, </em><em>torch.Tensor</em><em>, </em><em>list</em><em>]</em>) – Input samples to explain.</p></li>
<li><p><strong>kwargs</strong> – Additional arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[np.ndarray, list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.NearestNeighborMultiBaselineSHAP.shap_values">
<span class="sig-name descname"><span class="pre">shap_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/MBSHAP.html#NearestNeighborMultiBaselineSHAP.shap_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.NearestNeighborMultiBaselineSHAP.shap_values" title="Link to this definition">¶</a></dt>
<dd><p>Compute SHAP values using per-sample nearest neighbor baselines.</p>
<p>For each sample in <cite>X</cite>, this method:
1. Selects the <cite>n_baselines</cite> nearest neighbors from the background.
2. Instantiates the explainer with the selected baselines.
3. Computes SHAP values with respect to each baseline.
4. Averages SHAP values across baselines to produce a robust explanation.</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\phi(x) = \frac{1}{K} \sum_{k=1}^{K} \text{SHAP}(x | b_k)\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>np.ndarray</em>) – Input samples to explain, shape (N, …) or single sample (…).</p></li>
<li><p><strong>kwargs</strong> – Additional keyword arguments forwarded to the SHAP explainer.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Averaged SHAP attributions, shape (N, …) or (…) for single input.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="shap_enhanced.explainers.RLShapExplainer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">shap_enhanced.explainers.</span></span><span class="sig-name descname"><span class="pre">RLShapExplainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">background</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_hidden</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/RLSHAP.html#RLShapExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.RLShapExplainer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="shap_enhanced.base_explainer.html#shap_enhanced.base_explainer.BaseExplainer" title="shap_enhanced.base_explainer.BaseExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseExplainer</span></code></a></p>
<p>RLShapExplainer: Reinforcement Learning–based SHAP Explainer</p>
<p>This explainer uses a policy network trained via reinforcement learning to
learn feature–time masking strategies that optimize attribution signal strength.
Instead of enumerating coalitions randomly, it learns where to mask for maximal
model impact and uses those masks to approximate SHAP values.</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\text{SHAP}(i) \approx \mathbb{E}_{\pi} \left[
    f(x \setminus i) - f(x)
\right]\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The predictive model to be explained.</p></li>
<li><p><strong>background</strong> (<em>np.ndarray</em><em> or </em><em>torch.Tensor</em>) – Background dataset used for mean imputation.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – Torch device, either ‘cpu’ or ‘cuda’.</p></li>
<li><p><strong>policy_hidden</strong> (<em>int</em>) – Hidden layer size for the masking policy network.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="shap_enhanced.explainers.RLShapExplainer.expected_value">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">expected_value</span></span><a class="headerlink" href="#shap_enhanced.explainers.RLShapExplainer.expected_value" title="Link to this definition">¶</a></dt>
<dd><p>Optional property returning the expected model output on the background dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expected value if defined by the subclass, else None.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.RLShapExplainer.explain">
<span class="sig-name descname"><span class="pre">explain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap_enhanced.explainers.RLShapExplainer.explain" title="Link to this definition">¶</a></dt>
<dd><p>Alias to <cite>shap_values</cite> for flexibility and API compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Union</em><em>[</em><em>np.ndarray</em><em>, </em><em>torch.Tensor</em><em>, </em><em>list</em><em>]</em>) – Input samples to explain.</p></li>
<li><p><strong>kwargs</strong> – Additional arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[np.ndarray, list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.RLShapExplainer.gumbel_sample">
<span class="sig-name descname"><span class="pre">gumbel_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/RLSHAP.html#RLShapExplainer.gumbel_sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.RLShapExplainer.gumbel_sample" title="Link to this definition">¶</a></dt>
<dd><p>Perform Gumbel-Softmax sampling over logits to generate differentiable binary-like masks.</p>
<p>Adds Gumbel noise to logits and applies a sigmoid activation with temperature scaling
to approximate binary sampling in a differentiable way.</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[y = \sigma\left(\frac{\logits + G}{\tau}\right), \quad
G \sim \text{Gumbel}(0,1)\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logits</strong> (<em>torch.Tensor</em>) – Raw logits over the (T, F) feature mask space.</p></li>
<li><p><strong>tau</strong> (<em>float</em>) – Temperature parameter controlling sharpness of output (lower = harder mask).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Differentiable soft mask tensor in [0, 1], same shape as logits.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.RLShapExplainer.shap_values">
<span class="sig-name descname"><span class="pre">shap_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nsamples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_frac</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/RLSHAP.html#RLShapExplainer.shap_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.RLShapExplainer.shap_values" title="Link to this definition">¶</a></dt>
<dd><p>Estimate SHAP values for input <cite>X</cite> using the trained masking policy.</p>
<p>For each feature (t, f), multiple masks are sampled with the feature masked and unmasked.
The expected difference in model outputs estimates the marginal contribution of the feature.</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\phi_{t,f} = \mathbb{E}_{m \sim \pi} \left[
    f(x_{m \cup \{(t,f)\}}) - f(x_m)
\right]\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>np.ndarray</em><em> or </em><em>torch.Tensor</em>) – Input to explain, shape (T, F) or (B, T, F).</p></li>
<li><p><strong>nsamples</strong> (<em>int</em>) – Number of mask samples to average over.</p></li>
<li><p><strong>mask_frac</strong> (<em>float</em>) – Fraction of features masked per sample.</p></li>
<li><p><strong>tau</strong> (<em>float</em>) – Gumbel-Softmax temperature.</p></li>
<li><p><strong>kwargs</strong> – Additional keyword arguments (not used).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Estimated SHAP values with same shape as input.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.RLShapExplainer.train_policy">
<span class="sig-name descname"><span class="pre">train_policy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_frac</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/RLSHAP.html#RLShapExplainer.train_policy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.RLShapExplainer.train_policy" title="Link to this definition">¶</a></dt>
<dd><p>Train the masking policy network using policy gradient optimization.</p>
<p>The network is optimized to generate masks that maximize the absolute
change in the model’s prediction when masking certain input features.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Gumbel-Softmax is used to approximate discrete mask sampling for differentiability.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_steps</strong> (<em>int</em>) – Number of training iterations.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Batch size sampled from the background at each step.</p></li>
<li><p><strong>mask_frac</strong> (<em>float</em>) – Fraction of features to mask in each sampled coalition.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="shap_enhanced.explainers.SparseCoalitionSHAPExplainer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">shap_enhanced.explainers.</span></span><span class="sig-name descname"><span class="pre">SparseCoalitionSHAPExplainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">background</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">onehot_groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'zero'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/SCSHAP.html#SparseCoalitionSHAPExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.SparseCoalitionSHAPExplainer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="shap_enhanced.base_explainer.html#shap_enhanced.base_explainer.BaseExplainer" title="shap_enhanced.base_explainer.BaseExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseExplainer</span></code></a></p>
<p>SparseCoalitionSHAPExplainer: Valid SHAP for Structured Sparse Inputs</p>
<p>This explainer approximates Shapley values by sampling valid sparse coalitions of features.
It ensures that perturbed inputs remain syntactically valid, especially for inputs with
structured sparsity such as one-hot encodings or binary indicator features.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>One-hot groups are masked as entire sets to simulate “no class selected”.
General binary features are masked element-wise.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>Any</em>) – Predictive model to explain.</p></li>
<li><p><strong>background</strong> (<em>np.ndarray</em><em> or </em><em>torch.Tensor</em>) – Background data (not directly used but required for base class).</p></li>
<li><p><strong>onehot_groups</strong> (<em>list</em><em>[</em><em>list</em><em>[</em><em>int</em><em>]</em><em>] or </em><em>None</em>) – List of one-hot index groups, e.g., [[0,1,2], [3,4]].</p></li>
<li><p><strong>mask_strategy</strong> (<em>str</em>) – Currently supports only “zero” masking.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – Device context for evaluation (e.g., ‘cuda’ or ‘cpu’).</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="shap_enhanced.explainers.SparseCoalitionSHAPExplainer.expected_value">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">expected_value</span></span><a class="headerlink" href="#shap_enhanced.explainers.SparseCoalitionSHAPExplainer.expected_value" title="Link to this definition">¶</a></dt>
<dd><p>Optional property returning the expected model output on the background dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expected value if defined by the subclass, else None.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.SparseCoalitionSHAPExplainer.explain">
<span class="sig-name descname"><span class="pre">explain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap_enhanced.explainers.SparseCoalitionSHAPExplainer.explain" title="Link to this definition">¶</a></dt>
<dd><p>Alias to <cite>shap_values</cite> for flexibility and API compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Union</em><em>[</em><em>np.ndarray</em><em>, </em><em>torch.Tensor</em><em>, </em><em>list</em><em>]</em>) – Input samples to explain.</p></li>
<li><p><strong>kwargs</strong> – Additional arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[np.ndarray, list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.SparseCoalitionSHAPExplainer.shap_values">
<span class="sig-name descname"><span class="pre">shap_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nsamples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_additivity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/SCSHAP.html#SparseCoalitionSHAPExplainer.shap_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.SparseCoalitionSHAPExplainer.shap_values" title="Link to this definition">¶</a></dt>
<dd><p>Estimate SHAP values using sparse-valid coalitions.</p>
<p>For each input sample:
- Iterates over all features (or one-hot groups).
- Randomly samples subsets of other features/groups to form coalitions.
- Computes model output difference when adding the current feature/group to the coalition.
- Averages these differences to estimate the Shapley value.</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\phi_i = \mathbb{E}_{S \subseteq N \setminus \{i\}} \left[
    f(S \cup \{i\}) - f(S)
\right]\]</div>
</div>
<p>Final attributions are normalized such that:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\sum_i \phi_i = f(x) - f(x_{\text{masked}})\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>np.ndarray</em><em> or </em><em>torch.Tensor</em>) – Input instance(s), shape (T, F) or (B, T, F).</p></li>
<li><p><strong>nsamples</strong> (<em>int</em>) – Number of coalition samples per feature/group.</p></li>
<li><p><strong>check_additivity</strong> (<em>bool</em>) – If True, prints the additivity check.</p></li>
<li><p><strong>random_seed</strong> (<em>int</em>) – Seed for reproducible sampling.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP attribution values, same shape as input.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="shap_enhanced.explainers.SupportPreservingSHAPExplainer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">shap_enhanced.explainers.</span></span><span class="sig-name descname"><span class="pre">SupportPreservingSHAPExplainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">background</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_unmatched</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/SPSHAP.html#SupportPreservingSHAPExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.SupportPreservingSHAPExplainer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="shap_enhanced.base_explainer.html#shap_enhanced.base_explainer.BaseExplainer" title="shap_enhanced.base_explainer.BaseExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseExplainer</span></code></a></p>
<p>SupportPreservingSHAPExplainer: Real-Pattern-Constrained SHAP Estimator</p>
<p>This explainer approximates SHAP values by generating only masked inputs that match real examples
in the dataset—preserving the discrete or sparse structure of the input space. It avoids
out-of-distribution perturbations by requiring coalitions (masked variants) to have binary
support patterns that exist in the original data.</p>
<p>If the data is not sparse (e.g., continuous), the method falls back to mean-masking,
akin to standard SHAP explainers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>Any</em>) – Predictive model to explain.</p></li>
<li><p><strong>background</strong> (<em>np.ndarray</em><em> or </em><em>torch.Tensor</em>) – Dataset used to match support patterns (shape: (N, T, F) or (N, F)).</p></li>
<li><p><strong>skip_unmatched</strong> (<em>bool</em>) – If True, coalitions without support-matching background samples are skipped.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – Device to evaluate model on (‘cpu’ or ‘cuda’).</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="shap_enhanced.explainers.SupportPreservingSHAPExplainer.expected_value">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">expected_value</span></span><a class="headerlink" href="#shap_enhanced.explainers.SupportPreservingSHAPExplainer.expected_value" title="Link to this definition">¶</a></dt>
<dd><p>Optional property returning the expected model output on the background dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expected value if defined by the subclass, else None.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.SupportPreservingSHAPExplainer.explain">
<span class="sig-name descname"><span class="pre">explain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap_enhanced.explainers.SupportPreservingSHAPExplainer.explain" title="Link to this definition">¶</a></dt>
<dd><p>Alias to <cite>shap_values</cite> for flexibility and API compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Union</em><em>[</em><em>np.ndarray</em><em>, </em><em>torch.Tensor</em><em>, </em><em>list</em><em>]</em>) – Input samples to explain.</p></li>
<li><p><strong>kwargs</strong> – Additional arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[np.ndarray, list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.SupportPreservingSHAPExplainer.shap_values">
<span class="sig-name descname"><span class="pre">shap_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nsamples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_additivity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/SPSHAP.html#SupportPreservingSHAPExplainer.shap_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.SupportPreservingSHAPExplainer.shap_values" title="Link to this definition">¶</a></dt>
<dd><p>Compute SHAP values by evaluating only valid support-preserving perturbations.</p>
<p>For sparse inputs (e.g., one-hot or binary):</p>
<blockquote>
<div><ul class="simple">
<li><p>For each feature, sample coalitions of other features.</p></li>
<li><p>Construct masked inputs and locate matching background samples with same nonzero support.</p></li>
<li><p>Evaluate model differences with and without the feature of interest.</p></li>
<li><p>Average differences to estimate SHAP values.</p></li>
</ul>
</div></blockquote>
<p>For dense inputs:
- Fallback to standard mean-based masking for each feature individually.</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\phi_i = \mathbb{E}_{S \subseteq N \setminus \{i\}} \left[
    f(x_{S \cup \{i\}}) - f(x_S)
\right]\]</div>
</div>
<p>Final attributions are normalized such that:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\sum_i \phi_i = f(x) - f(x_{\text{masked}})\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>np.ndarray</em><em> or </em><em>torch.Tensor</em>) – Input sample or batch of shape (T, F) or (B, T, F).</p></li>
<li><p><strong>nsamples</strong> (<em>int</em>) – Number of coalition samples per feature.</p></li>
<li><p><strong>check_additivity</strong> (<em>bool</em>) – If True, prints sum of SHAP vs model output difference.</p></li>
<li><p><strong>random_seed</strong> (<em>int</em>) – Seed for reproducibility.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP attributions with same shape as input.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="shap_enhanced.explainers.SurrogateSHAPExplainer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">shap_enhanced.explainers.</span></span><span class="sig-name descname"><span class="pre">SurrogateSHAPExplainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">background</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_explainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regressor_class=&lt;class</span> <span class="pre">'sklearn.ensemble._forest.RandomForestRegressor'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regressor_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nsamples_base=100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_inputs=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_outputs=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/SurroSHAP.html#SurrogateSHAPExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.SurrogateSHAPExplainer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="shap_enhanced.base_explainer.html#shap_enhanced.base_explainer.BaseExplainer" title="shap_enhanced.base_explainer.BaseExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseExplainer</span></code></a></p>
<p>SurrogateSHAPExplainer: Fast SHAP Approximation via Supervised Regression</p>
<p>SurroSHAP accelerates SHAP attribution by training a surrogate regression model that maps
input features to SHAP attributions. This is useful when repeated SHAP computation is too
costly or when near-instant explanations are needed for deployment.</p>
<p>The surrogate model is trained on a background dataset where “true” SHAP values are first computed
using a base explainer (e.g., <cite>DeepExplainer</cite>, <cite>KernelExplainer</cite>), and then used as regression targets.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Any sklearn-style regressor can be used (e.g., <cite>RandomForestRegressor</cite>, <cite>KernelRidge</cite>, etc.).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>Any</em>) – Predictive model to be explained.</p></li>
<li><p><strong>background</strong> (<em>np.ndarray</em>) – Background dataset for training surrogate and computing SHAP targets. Shape: (N, T, F).</p></li>
<li><p><strong>base_explainer</strong> (<em>Any</em>) – A SHAP-style explainer instance (already constructed).</p></li>
<li><p><strong>regressor_class</strong> (<em>type</em>) – Regressor class implementing fit/predict API. Defaults to RandomForestRegressor.</p></li>
<li><p><strong>regressor_kwargs</strong> (<em>dict</em>) – Optional keyword arguments for the regressor.</p></li>
<li><p><strong>nsamples_base</strong> (<em>int</em>) – Number of SHAP samples used for each background point.</p></li>
<li><p><strong>scale_inputs</strong> (<em>bool</em>) – Whether to standardize input features during training.</p></li>
<li><p><strong>scale_outputs</strong> (<em>bool</em>) – Whether to standardize SHAP values during training.</p></li>
<li><p><strong>device</strong> (<em>str</em><em> or </em><em>torch.device</em>) – Torch device (e.g., ‘cpu’ or ‘cuda’).</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="shap_enhanced.explainers.SurrogateSHAPExplainer.expected_value">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">expected_value</span></span><a class="headerlink" href="#shap_enhanced.explainers.SurrogateSHAPExplainer.expected_value" title="Link to this definition">¶</a></dt>
<dd><p>Optional property returning the expected model output on the background dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expected value if defined by the subclass, else None.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.SurrogateSHAPExplainer.explain">
<span class="sig-name descname"><span class="pre">explain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap_enhanced.explainers.SurrogateSHAPExplainer.explain" title="Link to this definition">¶</a></dt>
<dd><p>Alias to <cite>shap_values</cite> for flexibility and API compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Union</em><em>[</em><em>np.ndarray</em><em>, </em><em>torch.Tensor</em><em>, </em><em>list</em><em>]</em>) – Input samples to explain.</p></li>
<li><p><strong>kwargs</strong> – Additional arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[np.ndarray, list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.SurrogateSHAPExplainer.shap_values">
<span class="sig-name descname"><span class="pre">shap_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/SurroSHAP.html#SurrogateSHAPExplainer.shap_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.SurrogateSHAPExplainer.shap_values" title="Link to this definition">¶</a></dt>
<dd><p>Predict SHAP attributions for new inputs using the trained surrogate model.</p>
<p>The input is reshaped and (optionally) standardized to match the format used
during surrogate training, and the predicted SHAP values are inverse-transformed
(if scaling was applied).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This bypasses SHAP computation entirely and relies on the surrogate regressor.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>np.ndarray</em><em> or </em><em>torch.Tensor</em>) – Input instance or batch, shape (T, F) or (B, T, F).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Approximated SHAP attributions, same shape as input.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="shap_enhanced.explainers.TimeSHAPExplainer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">shap_enhanced.explainers.</span></span><span class="sig-name descname"><span class="pre">TimeSHAPExplainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">background</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_window</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_topk</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/TimeSHAP.html#TimeSHAPExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.TimeSHAPExplainer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="shap_enhanced.base_explainer.html#shap_enhanced.base_explainer.BaseExplainer" title="shap_enhanced.base_explainer.BaseExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseExplainer</span></code></a></p>
<p>TimeSHAPExplainer: Pruned SHAP Attribution for Sequential Models</p>
<p>Implements a SHAP-style explainer for time-series and sequential data using pruning
to efficiently estimate per-(t, f) or event-level attributions.</p>
<dl class="simple">
<dt>Combines:</dt><dd><ul class="simple">
<li><p>Masking strategy (zero or mean-based).</p></li>
<li><p>Optional event windowing (for segment-level attribution).</p></li>
<li><p>Top-k pruning to reduce the coalition space before final SHAP estimation.</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>Any</em>) – The model to be explained.</p></li>
<li><p><strong>background</strong> (<em>np.ndarray</em><em> or </em><em>torch.Tensor</em>) – Background dataset for imputation and mean estimation.</p></li>
<li><p><strong>mask_strategy</strong> (<em>str</em>) – Masking method, either ‘zero’ or ‘mean’.</p></li>
<li><p><strong>event_window</strong> (<em>int</em><em> or </em><em>None</em>) – Optional window size for event-based attribution.</p></li>
<li><p><strong>prune_topk</strong> (<em>int</em><em> or </em><em>None</em>) – If specified, retain only top-k units (based on rough attribution) for refinement.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – Computation device (‘cpu’ or ‘cuda’).</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="shap_enhanced.explainers.TimeSHAPExplainer.expected_value">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">expected_value</span></span><a class="headerlink" href="#shap_enhanced.explainers.TimeSHAPExplainer.expected_value" title="Link to this definition">¶</a></dt>
<dd><p>Optional property returning the expected model output on the background dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Expected value if defined by the subclass, else None.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.TimeSHAPExplainer.explain">
<span class="sig-name descname"><span class="pre">explain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap_enhanced.explainers.TimeSHAPExplainer.explain" title="Link to this definition">¶</a></dt>
<dd><p>Alias to <cite>shap_values</cite> for flexibility and API compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Union</em><em>[</em><em>np.ndarray</em><em>, </em><em>torch.Tensor</em><em>, </em><em>list</em><em>]</em>) – Input samples to explain.</p></li>
<li><p><strong>kwargs</strong> – Additional arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[np.ndarray, list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap_enhanced.explainers.TimeSHAPExplainer.shap_values">
<span class="sig-name descname"><span class="pre">shap_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nsamples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'timestep'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_additivity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/shap_enhanced/explainers/TimeSHAP.html#TimeSHAPExplainer.shap_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#shap_enhanced.explainers.TimeSHAPExplainer.shap_values" title="Link to this definition">¶</a></dt>
<dd><p>Compute SHAP values for sequential input with optional pruning and window-based attribution.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Pruned estimation uses an initial coarse pass to identify important units
(features, timesteps, or windows), followed by refined SHAP estimation over that subset.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Union</em><em>[</em><em>np.ndarray</em><em>, </em><em>torch.Tensor</em><em>]</em>) – Input tensor or array of shape (T, F) or (B, T, F).</p></li>
<li><p><strong>nsamples</strong> (<em>int</em>) – Number of coalitions to sample per unit.</p></li>
<li><p><strong>level</strong> (<em>str</em>) – Attribution level: ‘timestep’, ‘feature’, or ‘event’.</p></li>
<li><p><strong>check_additivity</strong> (<em>bool</em>) – If True, print additivity diagnostics.</p></li>
<li><p><strong>random_seed</strong> (<em>int</em>) – Random seed for reproducibility.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SHAP values with shape (T, F) or (B, T, F).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<p class="rubric">Modules</p>
<div class="table-wrapper autosummary longtable docutils container">
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="shap_enhanced.explainers.ABSHAP.html#module-shap_enhanced.explainers.ABSHAP" title="shap_enhanced.explainers.ABSHAP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ABSHAP</span></code></a></p></td>
<td><p>Adaptive Baseline SHAP (Sparse)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="shap_enhanced.explainers.AttnSHAP.html#module-shap_enhanced.explainers.AttnSHAP" title="shap_enhanced.explainers.AttnSHAP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AttnSHAP</span></code></a></p></td>
<td><p>AttnSHAPExplainer: Attention-Guided SHAP with General Proxy Attention</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="shap_enhanced.explainers.BSHAP.html#module-shap_enhanced.explainers.BSHAP" title="shap_enhanced.explainers.BSHAP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BSHAP</span></code></a></p></td>
<td><p>BShapExplainer: Distribution-Free SHAP for Sequential Models</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="shap_enhanced.explainers.CASHAP.html#module-shap_enhanced.explainers.CASHAP" title="shap_enhanced.explainers.CASHAP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CASHAP</span></code></a></p></td>
<td><p>CASHAP: Coalition-Aware SHAP Explainer</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="shap_enhanced.explainers.CMSHAP.html#module-shap_enhanced.explainers.CMSHAP" title="shap_enhanced.explainers.CMSHAP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CMSHAP</span></code></a></p></td>
<td><p>Contextual Masking SHAP (CM-SHAP) Explainer for Sequential Models</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="shap_enhanced.explainers.ECSHAP.html#module-shap_enhanced.explainers.ECSHAP" title="shap_enhanced.explainers.ECSHAP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ECSHAP</span></code></a></p></td>
<td><p>EC-SHAP: Empirical Conditional SHAP for Discrete Data</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="shap_enhanced.explainers.ERSHAP.html#module-shap_enhanced.explainers.ERSHAP" title="shap_enhanced.explainers.ERSHAP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ERSHAP</span></code></a></p></td>
<td><p>ER-SHAP: Ensemble of Random SHAP Explainer</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="shap_enhanced.explainers.ESSHAP.html#module-shap_enhanced.explainers.ESSHAP" title="shap_enhanced.explainers.ESSHAP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ESSHAP</span></code></a></p></td>
<td><p>EnsembleSHAPWithNoise: Robust Ensemble Wrapper for SHAP/Custom Explainers</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="shap_enhanced.explainers.LatentSHAP.html#module-shap_enhanced.explainers.LatentSHAP" title="shap_enhanced.explainers.LatentSHAP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LatentSHAP</span></code></a></p></td>
<td><p>Latent SHAP with Autoencoding for Structured Time Series</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="shap_enhanced.explainers.MBSHAP.html#module-shap_enhanced.explainers.MBSHAP" title="shap_enhanced.explainers.MBSHAP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MBSHAP</span></code></a></p></td>
<td><p>MB-SHAP: Multi-Baseline SHAP Explainer</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="shap_enhanced.explainers.RLSHAP.html#module-shap_enhanced.explainers.RLSHAP" title="shap_enhanced.explainers.RLSHAP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RLSHAP</span></code></a></p></td>
<td><p>RL-SHAP: Reinforcement Learning SHAP Explainer</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="shap_enhanced.explainers.SCSHAP.html#module-shap_enhanced.explainers.SCSHAP" title="shap_enhanced.explainers.SCSHAP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SCSHAP</span></code></a></p></td>
<td><p>Sparse Coalition SHAP Explainer</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="shap_enhanced.explainers.SPSHAP.html#module-shap_enhanced.explainers.SPSHAP" title="shap_enhanced.explainers.SPSHAP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SPSHAP</span></code></a></p></td>
<td><p>Support-Preserving SHAP Explainer</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="shap_enhanced.explainers.SurroSHAP.html#module-shap_enhanced.explainers.SurroSHAP" title="shap_enhanced.explainers.SurroSHAP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SurroSHAP</span></code></a></p></td>
<td><p>SurroSHAP: Surrogate Model SHAP Explainer</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="shap_enhanced.explainers.TimeSHAP.html#module-shap_enhanced.explainers.TimeSHAP" title="shap_enhanced.explainers.TimeSHAP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TimeSHAP</span></code></a></p></td>
<td><p>TimeSHAP Explainer: Pruning-Enhanced SHAP for Sequential Models</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="shap_enhanced.explainers.hSHAP.html#module-shap_enhanced.explainers.hSHAP" title="shap_enhanced.explainers.hSHAP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hSHAP</span></code></a></p></td>
<td><p>h-SHAP: Hierarchical SHAP Explainer</p></td>
</tr>
</tbody>
</table>
</div>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="shap_enhanced.explainers.ABSHAP.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">shap_enhanced.explainers.ABSHAP</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="shap_enhanced.base_explainer.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">shap_enhanced.base_explainer</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2025, Niyang Bai
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">shap_enhanced.explainers</a><ul>
<li><a class="reference internal" href="#shap-explainers-collection">SHAP Explainers Collection</a><ul>
<li><a class="reference internal" href="#overview">Overview</a></li>
<li><a class="reference internal" href="#modules">Modules</a></li>
<li><a class="reference internal" href="#usage">Usage</a></li>
</ul>
</li>
<li><a class="reference internal" href="#shap_enhanced.explainers.AdaptiveBaselineSHAPExplainer"><code class="docutils literal notranslate"><span class="pre">AdaptiveBaselineSHAPExplainer</span></code></a><ul>
<li><a class="reference internal" href="#shap_enhanced.explainers.AdaptiveBaselineSHAPExplainer.expected_value"><code class="docutils literal notranslate"><span class="pre">AdaptiveBaselineSHAPExplainer.expected_value</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.AdaptiveBaselineSHAPExplainer.explain"><code class="docutils literal notranslate"><span class="pre">AdaptiveBaselineSHAPExplainer.explain()</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.AdaptiveBaselineSHAPExplainer.shap_values"><code class="docutils literal notranslate"><span class="pre">AdaptiveBaselineSHAPExplainer.shap_values()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#shap_enhanced.explainers.AttnSHAPExplainer"><code class="docutils literal notranslate"><span class="pre">AttnSHAPExplainer</span></code></a><ul>
<li><a class="reference internal" href="#shap_enhanced.explainers.AttnSHAPExplainer.expected_value"><code class="docutils literal notranslate"><span class="pre">AttnSHAPExplainer.expected_value</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.AttnSHAPExplainer.explain"><code class="docutils literal notranslate"><span class="pre">AttnSHAPExplainer.explain()</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.AttnSHAPExplainer.shap_values"><code class="docutils literal notranslate"><span class="pre">AttnSHAPExplainer.shap_values()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#shap_enhanced.explainers.BShapExplainer"><code class="docutils literal notranslate"><span class="pre">BShapExplainer</span></code></a><ul>
<li><a class="reference internal" href="#shap_enhanced.explainers.BShapExplainer.expected_value"><code class="docutils literal notranslate"><span class="pre">BShapExplainer.expected_value</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.BShapExplainer.explain"><code class="docutils literal notranslate"><span class="pre">BShapExplainer.explain()</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.BShapExplainer.shap_values"><code class="docutils literal notranslate"><span class="pre">BShapExplainer.shap_values()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#shap_enhanced.explainers.CoalitionAwareSHAPExplainer"><code class="docutils literal notranslate"><span class="pre">CoalitionAwareSHAPExplainer</span></code></a><ul>
<li><a class="reference internal" href="#shap_enhanced.explainers.CoalitionAwareSHAPExplainer.expected_value"><code class="docutils literal notranslate"><span class="pre">CoalitionAwareSHAPExplainer.expected_value</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.CoalitionAwareSHAPExplainer.explain"><code class="docutils literal notranslate"><span class="pre">CoalitionAwareSHAPExplainer.explain()</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.CoalitionAwareSHAPExplainer.shap_values"><code class="docutils literal notranslate"><span class="pre">CoalitionAwareSHAPExplainer.shap_values()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#shap_enhanced.explainers.ContextualMaskingSHAPExplainer"><code class="docutils literal notranslate"><span class="pre">ContextualMaskingSHAPExplainer</span></code></a><ul>
<li><a class="reference internal" href="#shap_enhanced.explainers.ContextualMaskingSHAPExplainer.expected_value"><code class="docutils literal notranslate"><span class="pre">ContextualMaskingSHAPExplainer.expected_value</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.ContextualMaskingSHAPExplainer.explain"><code class="docutils literal notranslate"><span class="pre">ContextualMaskingSHAPExplainer.explain()</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.ContextualMaskingSHAPExplainer.shap_values"><code class="docutils literal notranslate"><span class="pre">ContextualMaskingSHAPExplainer.shap_values()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#shap_enhanced.explainers.ERSHAPExplainer"><code class="docutils literal notranslate"><span class="pre">ERSHAPExplainer</span></code></a><ul>
<li><a class="reference internal" href="#shap_enhanced.explainers.ERSHAPExplainer.expected_value"><code class="docutils literal notranslate"><span class="pre">ERSHAPExplainer.expected_value</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.ERSHAPExplainer.explain"><code class="docutils literal notranslate"><span class="pre">ERSHAPExplainer.explain()</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.ERSHAPExplainer.shap_values"><code class="docutils literal notranslate"><span class="pre">ERSHAPExplainer.shap_values()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#shap_enhanced.explainers.EmpiricalConditionalSHAPExplainer"><code class="docutils literal notranslate"><span class="pre">EmpiricalConditionalSHAPExplainer</span></code></a><ul>
<li><a class="reference internal" href="#shap_enhanced.explainers.EmpiricalConditionalSHAPExplainer.expected_value"><code class="docutils literal notranslate"><span class="pre">EmpiricalConditionalSHAPExplainer.expected_value</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.EmpiricalConditionalSHAPExplainer.explain"><code class="docutils literal notranslate"><span class="pre">EmpiricalConditionalSHAPExplainer.explain()</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.EmpiricalConditionalSHAPExplainer.shap_values"><code class="docutils literal notranslate"><span class="pre">EmpiricalConditionalSHAPExplainer.shap_values()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#shap_enhanced.explainers.EnsembleSHAPWithNoise"><code class="docutils literal notranslate"><span class="pre">EnsembleSHAPWithNoise</span></code></a><ul>
<li><a class="reference internal" href="#shap_enhanced.explainers.EnsembleSHAPWithNoise.expected_value"><code class="docutils literal notranslate"><span class="pre">EnsembleSHAPWithNoise.expected_value</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.EnsembleSHAPWithNoise.explain"><code class="docutils literal notranslate"><span class="pre">EnsembleSHAPWithNoise.explain()</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.EnsembleSHAPWithNoise.shap_values"><code class="docutils literal notranslate"><span class="pre">EnsembleSHAPWithNoise.shap_values()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#shap_enhanced.explainers.HShapExplainer"><code class="docutils literal notranslate"><span class="pre">HShapExplainer</span></code></a><ul>
<li><a class="reference internal" href="#shap_enhanced.explainers.HShapExplainer.expected_value"><code class="docutils literal notranslate"><span class="pre">HShapExplainer.expected_value</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.HShapExplainer.explain"><code class="docutils literal notranslate"><span class="pre">HShapExplainer.explain()</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.HShapExplainer.shap_values"><code class="docutils literal notranslate"><span class="pre">HShapExplainer.shap_values()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#shap_enhanced.explainers.LatentSHAPExplainer"><code class="docutils literal notranslate"><span class="pre">LatentSHAPExplainer</span></code></a><ul>
<li><a class="reference internal" href="#shap_enhanced.explainers.LatentSHAPExplainer.expected_value"><code class="docutils literal notranslate"><span class="pre">LatentSHAPExplainer.expected_value</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.LatentSHAPExplainer.explain"><code class="docutils literal notranslate"><span class="pre">LatentSHAPExplainer.explain()</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.LatentSHAPExplainer.shap_values"><code class="docutils literal notranslate"><span class="pre">LatentSHAPExplainer.shap_values()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#shap_enhanced.explainers.NearestNeighborMultiBaselineSHAP"><code class="docutils literal notranslate"><span class="pre">NearestNeighborMultiBaselineSHAP</span></code></a><ul>
<li><a class="reference internal" href="#shap_enhanced.explainers.NearestNeighborMultiBaselineSHAP.expected_value"><code class="docutils literal notranslate"><span class="pre">NearestNeighborMultiBaselineSHAP.expected_value</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.NearestNeighborMultiBaselineSHAP.explain"><code class="docutils literal notranslate"><span class="pre">NearestNeighborMultiBaselineSHAP.explain()</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.NearestNeighborMultiBaselineSHAP.shap_values"><code class="docutils literal notranslate"><span class="pre">NearestNeighborMultiBaselineSHAP.shap_values()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#shap_enhanced.explainers.RLShapExplainer"><code class="docutils literal notranslate"><span class="pre">RLShapExplainer</span></code></a><ul>
<li><a class="reference internal" href="#shap_enhanced.explainers.RLShapExplainer.expected_value"><code class="docutils literal notranslate"><span class="pre">RLShapExplainer.expected_value</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.RLShapExplainer.explain"><code class="docutils literal notranslate"><span class="pre">RLShapExplainer.explain()</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.RLShapExplainer.gumbel_sample"><code class="docutils literal notranslate"><span class="pre">RLShapExplainer.gumbel_sample()</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.RLShapExplainer.shap_values"><code class="docutils literal notranslate"><span class="pre">RLShapExplainer.shap_values()</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.RLShapExplainer.train_policy"><code class="docutils literal notranslate"><span class="pre">RLShapExplainer.train_policy()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#shap_enhanced.explainers.SparseCoalitionSHAPExplainer"><code class="docutils literal notranslate"><span class="pre">SparseCoalitionSHAPExplainer</span></code></a><ul>
<li><a class="reference internal" href="#shap_enhanced.explainers.SparseCoalitionSHAPExplainer.expected_value"><code class="docutils literal notranslate"><span class="pre">SparseCoalitionSHAPExplainer.expected_value</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.SparseCoalitionSHAPExplainer.explain"><code class="docutils literal notranslate"><span class="pre">SparseCoalitionSHAPExplainer.explain()</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.SparseCoalitionSHAPExplainer.shap_values"><code class="docutils literal notranslate"><span class="pre">SparseCoalitionSHAPExplainer.shap_values()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#shap_enhanced.explainers.SupportPreservingSHAPExplainer"><code class="docutils literal notranslate"><span class="pre">SupportPreservingSHAPExplainer</span></code></a><ul>
<li><a class="reference internal" href="#shap_enhanced.explainers.SupportPreservingSHAPExplainer.expected_value"><code class="docutils literal notranslate"><span class="pre">SupportPreservingSHAPExplainer.expected_value</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.SupportPreservingSHAPExplainer.explain"><code class="docutils literal notranslate"><span class="pre">SupportPreservingSHAPExplainer.explain()</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.SupportPreservingSHAPExplainer.shap_values"><code class="docutils literal notranslate"><span class="pre">SupportPreservingSHAPExplainer.shap_values()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#shap_enhanced.explainers.SurrogateSHAPExplainer"><code class="docutils literal notranslate"><span class="pre">SurrogateSHAPExplainer</span></code></a><ul>
<li><a class="reference internal" href="#shap_enhanced.explainers.SurrogateSHAPExplainer.expected_value"><code class="docutils literal notranslate"><span class="pre">SurrogateSHAPExplainer.expected_value</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.SurrogateSHAPExplainer.explain"><code class="docutils literal notranslate"><span class="pre">SurrogateSHAPExplainer.explain()</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.SurrogateSHAPExplainer.shap_values"><code class="docutils literal notranslate"><span class="pre">SurrogateSHAPExplainer.shap_values()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#shap_enhanced.explainers.TimeSHAPExplainer"><code class="docutils literal notranslate"><span class="pre">TimeSHAPExplainer</span></code></a><ul>
<li><a class="reference internal" href="#shap_enhanced.explainers.TimeSHAPExplainer.expected_value"><code class="docutils literal notranslate"><span class="pre">TimeSHAPExplainer.expected_value</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.TimeSHAPExplainer.explain"><code class="docutils literal notranslate"><span class="pre">TimeSHAPExplainer.explain()</span></code></a></li>
<li><a class="reference internal" href="#shap_enhanced.explainers.TimeSHAPExplainer.shap_values"><code class="docutils literal notranslate"><span class="pre">TimeSHAPExplainer.shap_values()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=46bd48cc"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </body>
</html>
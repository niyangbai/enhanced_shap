{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97008c0f",
   "metadata": {},
   "source": [
    "# Shapley Value Attribution for Tabular Models\n",
    "\n",
    "This document provides a formal, academic presentation of Shapley value attributions for feed-forward neural networks on tabular data. We derive the Shapley definition, present an unbiased Monte Carlo estimator for ground-truth values, describe the SHAP DeepExplainer methodology, and outline a side-by-side bar-chart comparison protocol.\n",
    "\n",
    "## 1. Introduction\n",
    "Interpreting feature contributions in tabular models is essential for model transparency. Shapley values, originating from cooperative game theory, offer a principled way to assign each feature its average marginal impact. We demonstrate how to compute exact Shapley attributions via Monte Carlo sampling and approximate them efficiently using the SHAP DeepExplainer.\n",
    "\n",
    "## 2. Formal Definition\n",
    "Let:\n",
    "\n",
    "- $F$ be the number of features  \n",
    "- $N = \\{1, 2, \\dots, F\\}$ the feature index set  \n",
    "- $x \\in \\mathbb{R}^F$ a specific input vector  \n",
    "- $f : \\mathbb{R}^F \\to \\mathbb{R}$ the model’s scalar output  \n",
    "- $b \\in \\mathbb{R}^F$ the baseline vector (e.g., feature means)\n",
    "\n",
    "For any coalition $S \\subseteq N$, define the “masked” input:\n",
    "\n",
    "$$\n",
    "x_S[i] =\n",
    "\\begin{cases}\n",
    "x_i, & \\text{if } i \\in S \\\\\n",
    "b_i, & \\text{if } i \\notin S\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The Shapley value for feature $i$ is:\n",
    "\n",
    "$$\n",
    "\\phi_i =\n",
    "\\sum_{S \\subseteq N \\setminus \\{i\\}}\n",
    "\\frac{|S|! \\, (F - |S| - 1)!}{F!}\n",
    "\\left[ f(x_{S \\cup \\{i\\}}) - f(x_S) \\right]\n",
    "$$\n",
    "\n",
    "This formula ensures fair averaging of each feature’s marginal contribution across all subsets $S$.\n",
    "\n",
    "## 3. Unbiased Monte Carlo Estimation\n",
    "Exact evaluation requires $2^F$ function calls. Instead, approximate by sampling $M$ random coalitions:\n",
    "\n",
    "1. For $m = 1, \\dots, M$, draw $S_m \\subseteq N \\setminus \\{i\\}$ by including each feature $j \\ne i$ with probability 0.5.  \n",
    "2. Compute marginal contribution:  \n",
    "   $$\n",
    "   d_m = f(x_{S_m \\cup \\{i\\}}) - f(x_{S_m})\n",
    "   $$\n",
    "3. Estimate:  \n",
    "   $$\n",
    "   \\phi_i^{\\mathrm{MC}} \\approx \\frac{1}{M} \\sum_{m=1}^M d_m\n",
    "   $$\n",
    "\n",
    "By the law of large numbers, $\\phi_i^{\\mathrm{MC}} \\to \\phi_i$ as $M \\to \\infty$.\n",
    "\n",
    "## 4. SHAP DeepExplainer Method\n",
    "SHAP’s DeepExplainer uses a background dataset $X_b = \\{x'^{(1)}, \\dots, x'^{(K)}\\}$ to approximate the expected output:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[f(x')] \\approx \\frac{1}{K} \\sum_{k=1}^K f(x'^{(k)})\n",
    "$$\n",
    "\n",
    "It then computes attributions $\\psi_i(x)$ satisfying:\n",
    "\n",
    "$$\n",
    "f(x) = \\mathbb{E}[f(x')] + \\sum_{i=1}^F \\psi_i(x)\n",
    "$$\n",
    "\n",
    "Non‐linear activations are linearized around each background sample, and backpropagation aggregates contributions. The parameter `check_additivity=False` can be used to relax strict summation checks when necessary.\n",
    "\n",
    "## 5. Comparative Visualization Protocol\n",
    "To assess fidelity of $\\psi$ against $\\phi^{\\mathrm{MC}}$:\n",
    "\n",
    "1. Choose a test instance $x$  \n",
    "2. Compute $\\phi^{\\mathrm{MC}}(x) \\in \\mathbb{R}^F$ via Monte Carlo  \n",
    "3. Compute $\\psi(x) \\in \\mathbb{R}^F$ with DeepExplainer  \n",
    "4. Plot two side‐by‐side bar charts:\n",
    "   - **X‐axis:** feature index $i$  \n",
    "   - **Y‐axis:** attribution magnitude  \n",
    "   - **Left chart:** $\\phi_i^{\\mathrm{MC}}$  \n",
    "   - **Right chart:** $\\psi_i$\n",
    "\n",
    "Visual agreement indicates high fidelity of the DeepExplainer approximation.\n",
    "\n",
    "## 6. Discussion\n",
    "This exposition demonstrates that Shapley attributions apply seamlessly to tabular neural networks. The Monte Carlo estimator provides unbiased “ground truth,” while DeepExplainer offers an efficient, differentiable approximation. Comparative bar‐chart analysis highlights any discrepancies and guides practitioners in evaluating attribution reliability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a52e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import shap\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from shap_enhanced.tools.datasets import generate_synthetic_tabular\n",
    "from shap_enhanced.tools.predefined_models import TabularMLP\n",
    "from shap_enhanced.tools.evaluation import compute_shapley_gt_tabular\n",
    "from shap_enhanced.tools.visulization import plot_mse_pearson, plot_feature_comparison\n",
    "\n",
    "from shap_enhanced.explainers.ABSHAP import AdaptiveBaselineSHAPExplainer\n",
    "from shap_enhanced.explainers.ECSHAP import EmpiricalConditionalSHAPExplainer\n",
    "from shap_enhanced.explainers.SCSHAP import SparseCoalitionSHAPExplainer\n",
    "from shap_enhanced.explainers.SPSHAP import SupportPreservingSHAPExplainer\n",
    "\n",
    "# 1. Generate synthetic sparse tabular data (nonlinear by default)\n",
    "n_samples = 500\n",
    "n_features = 10\n",
    "X, y, true_w = generate_synthetic_tabular(\n",
    "    n_samples=n_samples,\n",
    "    n_features=n_features,\n",
    "    sparse=True,\n",
    "    model_type=\"nonlinear\",  # or \"linear\"\n",
    "    sparsity=0.8,            # higher for more zeros\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# 2. Define and train model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TabularMLP(input_dim=n_features, hidden_dim=24, output_dim=1).to(device)\n",
    "\n",
    "X_torch = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_torch = torch.tensor(y, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_fn(model(X_torch), y_torch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# 3. Select test instance and baseline\n",
    "x_test = X[0]\n",
    "x_baseline = X.mean(axis=0)\n",
    "\n",
    "# 4. Compute ground-truth SHAP values (Monte Carlo)\n",
    "shap_gt = compute_shapley_gt_tabular(\n",
    "    model, x_test, x_baseline, nsamples=500, device=device\n",
    ")\n",
    "\n",
    "# 5. Prepare background and explainer API\n",
    "background_pt = torch.tensor(X[:100], dtype=torch.float32).to(device)  # (100, 10)\n",
    "background_np = X[:100]\n",
    "\n",
    "def f_numpy(flat_x):\n",
    "    with torch.no_grad():\n",
    "        return model(torch.tensor(flat_x, dtype=torch.float32).to(device)).cpu().numpy()\n",
    "\n",
    "# 6. Define explainers (standard and adaptive)\n",
    "explainers = {\n",
    "    \"Deep\":      shap.DeepExplainer(model, background_pt),\n",
    "    \"Gradient\":  shap.GradientExplainer(model, background_pt),\n",
    "    \"Kernel\":    shap.KernelExplainer(f_numpy, background_np),\n",
    "    \"Partition\": shap.PartitionExplainer(f_numpy, background_np),\n",
    "    \"AdaptiveBaseline\": AdaptiveBaselineSHAPExplainer(\n",
    "        model=model,\n",
    "        background=background_pt,\n",
    "    ),\n",
    "    \"EmpCond\": EmpiricalConditionalSHAPExplainer(\n",
    "        model=model,\n",
    "        background=background_pt,\n",
    "        skip_unmatched=True,\n",
    "        use_closest=False,\n",
    "        device=device,\n",
    "    ),\n",
    "    \"SparseCoalition\": SparseCoalitionSHAPExplainer(\n",
    "        model=model,\n",
    "        background=background_pt,  # or background_np\n",
    "        onehot_groups=None,        # or [[0,1,2], [3,4,5]] for one-hot\n",
    "        mask_strategy=\"zero\",\n",
    "        device=device,\n",
    "    ),\n",
    "    \"SupportPreserving\": SupportPreservingSHAPExplainer(\n",
    "        model=model,\n",
    "        background=background_pt,\n",
    "        skip_unmatched=True,\n",
    "        device=device,\n",
    "    ),\n",
    "}\n",
    "\n",
    "# 7. Run explainers and collect attributions\n",
    "shap_models = {}\n",
    "for name, expl in explainers.items():\n",
    "    if name in (\"Deep\", \"Gradient\"):\n",
    "        input_tensor = torch.tensor(x_test[None], dtype=torch.float32).to(device)\n",
    "        if name == \"Deep\":\n",
    "            raw = expl.shap_values(input_tensor, check_additivity=False)\n",
    "        else:\n",
    "            raw = expl.shap_values(input_tensor)\n",
    "        vals = np.array(raw[0]).flatten()\n",
    "    elif name == \"Kernel\":\n",
    "        raw = expl.shap_values(x_test.reshape(1, -1))\n",
    "        vals = np.array(raw).flatten()\n",
    "    elif name == \"Partition\":\n",
    "        out = expl(x_test.reshape(1, -1))\n",
    "        vals = np.array(out.values).flatten()\n",
    "    elif name == \"AdaptiveBaseline\":\n",
    "        arr = expl.shap_values(x_test[None, :], nsamples=50)  # Use more samples for robustness if fast\n",
    "        vals = arr[0].flatten() if arr.ndim == 2 else arr.flatten()\n",
    "    elif name == \"EmpCond\":\n",
    "        # For tabular, treat as (T=1, F)\n",
    "        arr = expl.shap_values(x_test[None, :], nsamples=50)\n",
    "        vals = arr.flatten()\n",
    "    elif name == \"SparseCoalition\":\n",
    "        # For tabular: treat as (T=1, F)\n",
    "        arr = expl.shap_values(x_test[None, :], nsamples=50)\n",
    "        vals = arr.flatten()\n",
    "    elif name == \"SupportPreserving\":\n",
    "        arr = expl.shap_values(x_test[None, :], nsamples=20)\n",
    "        vals = arr.flatten()\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Unknown explainer: {name}\")\n",
    "    shap_models[name] = vals\n",
    "\n",
    "# 8. Compute MSE and Pearson correlation for each explainer\n",
    "results = {}\n",
    "pearson_results = {}\n",
    "for name, vals in shap_models.items():\n",
    "    mse = np.mean((vals - shap_gt) ** 2)\n",
    "    try:\n",
    "        pearson, _ = pearsonr(shap_gt, vals)\n",
    "    except Exception:\n",
    "        pearson = np.nan\n",
    "    results[name] = mse\n",
    "    pearson_results[name] = pearson\n",
    "\n",
    "# 9. Plot results\n",
    "plot_mse_pearson(results, pearson_results)\n",
    "plot_feature_comparison(shap_gt, shap_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4e8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def cache_plot_data(filename, results, pearson_results, shap_gt, shap_models):\n",
    "    \"\"\"\n",
    "    Cache all data needed for plotting to a pickle file.\n",
    "    \"\"\"\n",
    "    cache = {\n",
    "        \"results\": results,\n",
    "        \"pearson_results\": pearson_results,\n",
    "        \"shap_gt\": shap_gt,\n",
    "        \"shap_models\": shap_models,\n",
    "    }\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(cache, f)\n",
    "    print(f\"Plot data cached to {filename}\")\n",
    "\n",
    "cache_plot_data(\"tab.pkl\", results, pearson_results, shap_gt, shap_models)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

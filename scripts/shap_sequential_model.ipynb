{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "533695fb",
   "metadata": {},
   "source": [
    "# Shapley Value Attribution for Sequential (LSTM) Models\n",
    "\n",
    "This document presents a rigorous treatment of Shapley value attributions applied to Long Short-Term Memory (LSTM) neural networks. We elucidate the theoretical foundations, derive the formal definition for sequence data, describe unbiased Monte Carlo estimation of ground-truth values, and explain the adaptation of the SHAP DeepExplainer. Finally, we outline a methodology for comparative visualization and discuss the implications of interpretability in sequential models.\n",
    "\n",
    "## 1. Introduction\n",
    "Interpreting the contributions of individual inputs to a model’s prediction is critical for transparency in machine learning. While Shapley values are well established for static, tabular data, sequence models such as LSTMs pose a conceptual extension: each input element appears in temporal context. We treat each time–feature pair as an independent “player” in the Shapley game, enabling fair attribution across the entire sequence.\n",
    "\n",
    "## 2. Formal Definition for Sequence Attributions\n",
    "\n",
    "Let:\n",
    "\n",
    "- $T$ denote the length of the input sequence  \n",
    "- $F$ the feature dimension at each time step  \n",
    "- $N_{\\text{seq}} = \\{(t, i) : t = 1, \\dots, T;\\ i = 1, \\dots, F \\}$ the set of all time–feature pairs  \n",
    "- $x \\in \\mathbb{R}^{T \\times F}$ a specific input sequence  \n",
    "- $f : \\mathbb{R}^{T \\times F} \\to \\mathbb{R}$ the model’s scalar output  \n",
    "- $b \\in \\mathbb{R}^{T \\times F}$ the baseline sequence (e.g., empirical mean over reference set)\n",
    "\n",
    "For any coalition $S \\subseteq N_{\\text{seq}}$, define the masked sequence $x_S$ by:\n",
    "\n",
    "$$\n",
    "x_S[t, i] =\n",
    "\\begin{cases}\n",
    "x[t, i], & \\text{if } (t, i) \\in S \\\\\n",
    "b[t, i], & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The Shapley value for the cell $(t, i)$ is:\n",
    "\n",
    "$$\n",
    "\\phi_{t, i} =\n",
    "\\sum_{S \\subseteq N_{\\text{seq}} \\setminus \\{(t, i)\\}}\n",
    "\\frac{|S|! \\cdot (|N_{\\text{seq}}| - |S| - 1)!}{|N_{\\text{seq}}|!}\n",
    "\\left[ f(x_{S \\cup \\{(t, i)\\}}) - f(x_S) \\right]\n",
    "$$\n",
    "\n",
    "This ensures fair attribution across all possible input combinations and satisfies the axioms of efficiency, symmetry, nullity, and additivity.\n",
    "\n",
    "## 3. Unbiased Monte Carlo Estimation\n",
    "\n",
    "The exact summation spans $2^{T \\cdot F}$ coalitions, which becomes intractable. We instead use a Monte Carlo estimator:\n",
    "\n",
    "1. For each $(t, i)$ and $m = 1, \\dots, M$, sample $S_m \\subseteq N_{\\text{seq}} \\setminus \\{(t, i)\\}$ by including each other cell independently with probability 0.5  \n",
    "2. Compute marginal contributions:  \n",
    "   $$\n",
    "   d_m = f(x_{S_m \\cup \\{(t, i)\\}}) - f(x_{S_m})\n",
    "   $$\n",
    "3. Estimate:  \n",
    "   $$\n",
    "   \\phi_{t, i}^{\\text{MC}} \\approx \\frac{1}{M} \\sum_{m=1}^M d_m\n",
    "   $$\n",
    "\n",
    "By the law of large numbers, $\\phi_{t, i}^{\\text{MC}} \\to \\phi_{t, i}$ as $M \\to \\infty$.\n",
    "\n",
    "## 4. SHAP DeepExplainer Adaptation\n",
    "\n",
    "SHAP DeepExplainer uses a background set $X_b = \\{x'^{(1)}, \\dots, x'^{(K)}\\}$ to estimate:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{x' \\sim X_b}[f(x')] \\approx \\frac{1}{K} \\sum_{k=1}^K f(x'^{(k)})\n",
    "$$\n",
    "\n",
    "Then it computes attributions $\\psi_{t, i}(x)$ satisfying:\n",
    "\n",
    "$$\n",
    "f(x) = \\mathbb{E}[f(x')] + \\sum_{t=1}^T \\sum_{i=1}^F \\psi_{t, i}(x)\n",
    "$$\n",
    "\n",
    "Nonlinear recurrent operations are linearized via Taylor expansion around each background sample, and backpropagation aggregates the contributions. For LSTM internals, `check_additivity=False` can be set to disable exact-sum checking if the model structure leads to slight mismatches.\n",
    "\n",
    "## 5. Comparative Visualization Method\n",
    "\n",
    "To compare $\\phi^{\\text{MC}}$ and $\\psi$, we reshape both into $T \\times F$ matrices and visualize using 3D bar charts:\n",
    "\n",
    "- **Axes:** time index $t$, feature index $i$, attribution magnitude  \n",
    "- **Left Plot:** Monte Carlo estimate $\\phi_{t, i}^{\\text{MC}}$  \n",
    "- **Right Plot:** SHAP DeepExplainer attribution $\\psi_{t, i}$\n",
    "\n",
    "A close match between surfaces indicates high fidelity of the approximation.\n",
    "\n",
    "## 6. Discussion and Conclusion\n",
    "\n",
    "This exposition extends Shapley values to sequential models by treating time–feature positions as individual contributors. Monte Carlo sampling yields unbiased attributions, while DeepExplainer offers efficient, differentiable approximations. Visualization of attribution surfaces enables interpretation of temporal dynamics and helps validate explainer reliability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d6f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import shap\n",
    "\n",
    "from shap_enhanced.tools.predefined_models import RealisticLSTM\n",
    "from shap_enhanced.tools.datasets import generate_synthetic_seqregression\n",
    "from shap_enhanced.tools.evaluation import compute_shapley_gt_seq\n",
    "from shap_enhanced.tools.comparison import Comparison\n",
    "from shap_enhanced.tools.visulization import plot_mse_pearson, plot_3d_bars\n",
    "\n",
    "from shap_enhanced.explainers.CASHAP import CoalitionAwareSHAPExplainer\n",
    "from shap_enhanced.explainers.AttnSHAP import AttnSHAPExplainer\n",
    "from shap_enhanced.explainers.BSHAP import BShapExplainer\n",
    "from shap_enhanced.explainers.CMSHAP import ContextualMaskingSHAPExplainer\n",
    "from shap_enhanced.explainers.ESSHAP import EnsembleSHAPWithNoise\n",
    "from shap_enhanced.explainers.SurroSHAP import SurrogateSHAPExplainer\n",
    "from shap_enhanced.explainers.RLSHAP import RLShapExplainer\n",
    "from shap_enhanced.explainers.LatentSHAP import LatentSHAPExplainer, Conv1dEncoder, Conv1dDecoder, train_conv1d_autoencoder\n",
    "from shap_enhanced.explainers.MBSHAP import NearestNeighborMultiBaselineSHAP\n",
    "from shap_enhanced.explainers.TimeSHAP import TimeSHAPExplainer\n",
    "from shap_enhanced.explainers.ERSHAP import ERSHAPExplainer\n",
    "from shap_enhanced.explainers.hSHAP import HShapExplainer, generate_hierarchical_groups\n",
    "\n",
    "# 1. Generate synthetic sequential data\n",
    "seq_len, n_features, n_samples = 10, 3, 200\n",
    "X, y = generate_synthetic_seqregression(seq_len, n_features, n_samples)\n",
    "\n",
    "# 2. Train the LSTM model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RealisticLSTM(input_dim=n_features).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "X_t = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_t = torch.tensor(y, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    opt.zero_grad()\n",
    "    loss = loss_fn(model(X_t), y_t)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "# 3. Pick a test sample and a baseline\n",
    "x_test = X[0]\n",
    "x_baseline = X.mean(0)\n",
    "\n",
    "# 4. Compute Monte Carlo ground-truth SHAP values\n",
    "shap_gt = compute_shapley_gt_seq(model, x_test, x_baseline, nsamples=200, device=device)\n",
    "\n",
    "# 5. Define SHAP input functions\n",
    "def f_numpy(flat_x):\n",
    "    x = flat_x.reshape(-1, seq_len, n_features)\n",
    "    with torch.no_grad():\n",
    "        return model(torch.tensor(x, dtype=torch.float32).to(device)).cpu().numpy()\n",
    "\n",
    "bg_flat = X[:50].reshape(50, -1)\n",
    "background_pt = torch.tensor(X[:50], dtype=torch.float32).to(device)\n",
    "\n",
    "# 6. Instantiate explainers\n",
    "bshap_domain = (X[:50].reshape(-1, X.shape[-1]).min(axis=0), X[:50].reshape(-1, X.shape[-1]).max(axis=0)) # for 'uniform'\n",
    "# Or: bshap_domain = X[:50]                             # for 'marginal'\n",
    "\n",
    "rl_expl = RLShapExplainer(model, X[:50], device=device)\n",
    "rl_expl.train_policy(n_steps=500, batch_size=16, mask_frac=0.3)\n",
    "\n",
    "latent_dim = 4\n",
    "encoder = Conv1dEncoder(input_features=n_features, seq_len=seq_len, latent_dim=latent_dim)\n",
    "decoder = Conv1dDecoder(latent_dim=latent_dim, seq_len=seq_len, output_features=n_features)\n",
    "train_conv1d_autoencoder(encoder, decoder, X[:100], epochs=80, lr=1e-3, device=device)\n",
    "\n",
    "hierarchy = generate_hierarchical_groups(T=seq_len, F=n_features, time_block=2, feature_block=2)\n",
    "\n",
    "explainers = {\n",
    "    \"Deep\":      shap.DeepExplainer(model, background_pt),\n",
    "    \"Gradient\":  shap.GradientExplainer(model, background_pt),\n",
    "    \"Kernel\":    shap.KernelExplainer(f_numpy, bg_flat),\n",
    "    \"Partition\": shap.PartitionExplainer(f_numpy, bg_flat),\n",
    "    \"CASHAP\":    CoalitionAwareSHAPExplainer(\n",
    "        model=model, \n",
    "        background=X[:50],\n",
    "        mask_strategy=\"mean\",\n",
    "        device=device\n",
    "    ),\n",
    "    \"AttnSHAP\":  AttnSHAPExplainer(\n",
    "        model=model,\n",
    "        background=X[:50],\n",
    "        use_attention=True,\n",
    "        proxy_attention=\"gradient\",\n",
    "        device=device\n",
    "    ),\n",
    "    \"BShap\":     BShapExplainer(\n",
    "        model=model,\n",
    "        input_range=bshap_domain,\n",
    "        n_samples=30,\n",
    "        mask_strategy=\"random\",\n",
    "        device=device,\n",
    "    ),\n",
    "    \"CM-SHAP\":   ContextualMaskingSHAPExplainer(\n",
    "        model=model,\n",
    "        device=device\n",
    "    ),\n",
    "    \"Ensemble-Deep\": EnsembleSHAPWithNoise(\n",
    "        model=model,\n",
    "        background=X[:50],           # Must be torch.Tensor or np.ndarray as fits explainer\n",
    "        explainer_class=None,        # Defaults to shap.DeepExplainer\n",
    "        explainer_kwargs={},\n",
    "        n_runs=5,\n",
    "        noise_level=0.1,\n",
    "        noise_target=\"input\",        # Or \"background\" or \"both\"\n",
    "        aggregation=\"mean\",\n",
    "        device=device\n",
    "    ),\n",
    "    \"SurroSHAP\": SurrogateSHAPExplainer(\n",
    "        model=model,\n",
    "        background=X[:50],\n",
    "        base_explainer=shap.GradientExplainer(model, background_pt),\n",
    "    ),\n",
    "    \"RL-SHAP\": rl_expl,\n",
    "    \"LatentSHAP\": LatentSHAPExplainer(\n",
    "        model=model,\n",
    "        encoder=encoder,\n",
    "        decoder=decoder,\n",
    "        base_explainer_class=shap.GradientExplainer,   # or KernelExplainer for baseline\n",
    "        background=X[:50],     # Or any background subset\n",
    "        device=device,\n",
    "        base_explainer_kwargs={},\n",
    "    ),\n",
    "    \"MB-SHAP\": NearestNeighborMultiBaselineSHAP(\n",
    "        base_explainer_class=shap.DeepExplainer,   # or KernelExplainer, etc.\n",
    "        model=model,\n",
    "        background=background_pt,     # (N, T, F)\n",
    "        n_baselines=10,\n",
    "        base_explainer_kwargs={},  # extra args if needed\n",
    "    ),\n",
    "    \"TimeSHAP\": TimeSHAPExplainer(\n",
    "        model=model,\n",
    "        background=X[:50],            # or your background set\n",
    "        mask_strategy=\"mean\",         # or 'zero'\n",
    "        event_window=None,\n",
    "        prune_topk=None,\n",
    "        device=device\n",
    "    ),\n",
    "    \"ER-SHAP\":  ERSHAPExplainer(\n",
    "        model=model,\n",
    "        background=X[:50],           # Your background set\n",
    "        n_coalitions=30,             # Number of coalitions per feature\n",
    "        mask_strategy=\"mean\",        # or 'zero'\n",
    "        weighting=\"uniform\",         # or 'importance' or 'frequency'\n",
    "        feature_importance=None,     # Supply if using 'importance'\n",
    "        device=device\n",
    "    ),\n",
    "    \"h-SHAP\": HShapExplainer(\n",
    "        model=model,\n",
    "        background=X[:50],\n",
    "        hierarchy=hierarchy,\n",
    "        mask_strategy=\"mean\",\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "}\n",
    "\n",
    "def reshape_shap_arr(arr):\n",
    "    return arr.reshape(seq_len, n_features)\n",
    "\n",
    "# 7. Compute SHAP values for each explainer\n",
    "shap_models = {}\n",
    "for name, expl in explainers.items():\n",
    "    print(f\"Running {name}...\")\n",
    "    if name in [\"Deep\", \"Gradient\"]:\n",
    "        inp = torch.tensor(x_test[None], dtype=torch.float32, requires_grad=True).to(device)\n",
    "        if name == \"Deep\":\n",
    "            raw = expl.shap_values(inp, check_additivity=False)\n",
    "        else:\n",
    "            raw = expl.shap_values(inp)\n",
    "        if isinstance(raw, list):\n",
    "            raw = raw[0]\n",
    "        arr = reshape_shap_arr(raw)\n",
    "    elif name == \"Kernel\":\n",
    "        raw = expl.shap_values(x_test.reshape(1, -1))\n",
    "        arr = reshape_shap_arr(raw)\n",
    "    elif name == \"Partition\":\n",
    "        out = expl(x_test.reshape(1, -1))\n",
    "        arr = reshape_shap_arr(out.values[0])\n",
    "    elif name in [\"CASHAP\", \"AttnSHAP\"]:\n",
    "        arr = expl.shap_values(x_test, nsamples=20, coalition_size=6)\n",
    "    elif name == \"BShap\":\n",
    "        arr = expl.shap_values(x_test, check_additivity=True)\n",
    "    elif name == \"CM-SHAP\":\n",
    "        arr = expl.shap_values(x_test, nsamples=20, check_additivity=True)\n",
    "    elif name == \"Ensemble-Deep\":\n",
    "        arr = expl.shap_values(inp, check_additivity=False)\n",
    "        arr = reshape_shap_arr(arr)\n",
    "    elif name == \"SurroSHAP\":\n",
    "        arr = expl.shap_values(x_test)\n",
    "        arr = reshape_shap_arr(arr)\n",
    "    elif name == \"RL-SHAP\":\n",
    "        arr = expl.shap_values(x_test, nsamples=20, mask_frac=0.3, tau=0.5)\n",
    "    elif name == \"LatentSHAP\":\n",
    "        if x_test.ndim == 2:\n",
    "            x_test = x_test[None, ...] \n",
    "        arr = expl.shap_values(x_test)\n",
    "    elif name == \"MB-SHAP\":\n",
    "        arr = expl.shap_values(x_test)\n",
    "        arr = reshape_shap_arr(arr)\n",
    "    elif name == \"TimeSHAP\":\n",
    "        arr = expl.shap_values(x_test, nsamples=100, level=\"timestep\", check_additivity=True)\n",
    "    elif name == \"ER-SHAP\":\n",
    "        arr = expl.shap_values(x_test)\n",
    "        arr = reshape_shap_arr(arr)\n",
    "    elif name == \"h-SHAP\":\n",
    "        arr = expl.shap_values(x_test)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Unknown explainer: {name}\")\n",
    "    shap_models[name] = arr\n",
    "\n",
    "# 8. KPI comparison (MSE & Pearson)\n",
    "cmp = Comparison(ground_truth=shap_gt, shap_models=shap_models)\n",
    "results, pearson_results = cmp.calculate_kpis()\n",
    "\n",
    "# 9. Visualize KPIs and 3D bars\n",
    "plot_mse_pearson(results, pearson_results)\n",
    "plot_3d_bars(shap_gt, shap_models, seq_len, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3528196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def cache_all_plot_data(filename, results, pearson_results, shap_gt, shap_models, seq_len, n_features):\n",
    "    \"\"\"\n",
    "    Cache all data needed for plot_mse_pearson and plot_3d_bars to a pickle file.\n",
    "    \"\"\"\n",
    "    cache = {\n",
    "        \"results\": results,\n",
    "        \"pearson_results\": pearson_results,\n",
    "        \"shap_gt\": shap_gt,\n",
    "        \"shap_models\": shap_models,\n",
    "        \"seq_len\": seq_len,\n",
    "        \"n_features\": n_features,\n",
    "    }\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(cache, f)\n",
    "    print(f\"All plot data cached to {filename}\")\n",
    "\n",
    "# Usage:\n",
    "cache_all_plot_data(\"seq.pkl\", results, pearson_results, shap_gt, shap_models, seq_len, n_features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

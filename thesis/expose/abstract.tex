\begin{abstract}
This thesis proposes enhanced SHAP (Shapley Additive Explanations) methods tailored to the needs of Predictive Process Management (PPM), where interpretability is essential, and data often include sequential and sparse structures. For sequential data, the new approaches capture temporal dependencies, enabling a clearer understanding of how past events shape process predictions. For sparse data, optimized SHAP methods reduce dimensionality and computational demands while preserving interpretability. These advancements provide actionable insights into feature importance, supporting real-time, data-driven decisions in PPM and contributing to the broader field of explainable AI by addressing domain-specific challenges in complex, process-based environments. \footnote{The code for this thesis is available at: \href{https://github.com/niyangbai/SparseSHAP.git}{github.com/niyangbai/SparseSHAP.git}}
\end{abstract}